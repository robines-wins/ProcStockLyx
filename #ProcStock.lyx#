#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass book
\begin_preamble
\usepackage[pdftex,bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2]{hyperref}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Introduction to Stochastic Processes
\begin_inset Newline newline
\end_inset

MATH-447 McGiil
\end_layout

\begin_layout Author
Robin Solignac
\begin_inset Newline newline
\end_inset

MJ Lagarde
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
conditional probabilities, expectation.
 And probability generating function
\end_layout

\begin_layout Section
conditional probabilities and expectation, definitions
\end_layout

\begin_layout Standard
Definition: let's two random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 have a join discrete probability function 
\begin_inset Formula $P(x,y)=P(X=x,Y=y)$
\end_inset

 for 
\begin_inset Formula $(x,y)\subset A$
\end_inset

 (called the support of the distribution) and 
\begin_inset Formula $P(X=x,Y=y)=0\mbox{ for }(x,y)\notin A$
\end_inset

.
\end_layout

\begin_layout Standard
Then the conditional probability of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

, 
\begin_inset Formula $P_{y/X=x}(y|x)$
\end_inset

 is defined to be 
\begin_inset Formula $\frac{P_{X,Y}(x,y)}{P_{X}(x)}$
\end_inset

 for 
\begin_inset Formula $P_{X}(x)\neq0$
\end_inset

.
 Here 
\begin_inset Formula $P_{X}(x)$
\end_inset

 is called the marginal.
 
\begin_inset Formula $P_{X}(x)=\sum_{\forall y}P_{X,Y}(x,y)$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Notes : 
\end_layout

\begin_layout Enumerate
If you fix x, then 
\begin_inset Formula $P{}_{Y|X}(y|x)$
\end_inset

 consider as function of Y, defines a conditional probability distribution
 of Y given x.
\end_layout

\begin_layout Enumerate
There is no such thing as the random variable 
\begin_inset Formula $Y|X=x$
\end_inset

.
 It is simply defined as 
\begin_inset Formula $P(Y=y|X=x)$
\end_inset

 is defined as above.
 When you see the statement 
\begin_inset Formula $Y|X=x$
\end_inset

 don't interpret this to mean that that the r.v had the 
\begin_inset Formula $p$
\end_inset

 function 
\begin_inset Formula $P_{y/X=x}(y|X=x)$
\end_inset

.
 It means 
\begin_inset Formula $P_{y|X=x}(y|x)=P(Y=y|X=x)$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Definition 2: 
\end_layout

\begin_layout Standard
If the random variables 
\begin_inset Formula $(X,Y)$
\end_inset

 are jointly discrete, the conditional expectation of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

, written 
\begin_inset Formula $E(Y|X=x)$
\end_inset

 is defined as follows : 
\begin_inset Formula $E(Y|X=x)=\sum_{\forall y}y*P_{y/X=x}(y|x)$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Definition 3: 
\end_layout

\begin_layout Standard
If the random variables 
\begin_inset Formula $(X,Y)$
\end_inset

 are jointly continuous with probability density function (pdf) 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

 then we define conditional pdf of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

 as follows : 
\begin_inset Formula $f_{Y|X}=x(y|x)=\frac{fX,Y(x,y)}{fX(x)}$
\end_inset


\end_layout

\begin_layout Standard
Here 
\begin_inset Formula $\intop_{-\infty}^{\infty}f_{X,Y}(x,y)\,dy$
\end_inset

 is called marginal pdf of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Paragraph
Definition: 
\end_layout

\begin_layout Standard
If the r.v.
 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are continuous, with joint pdf 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

 then we define the conditional expectation of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

 as follows 
\begin_inset Formula $E(Y|X=x)=\intop_{-\infty}^{\infty}y*f_{Y|X=x}(y|x)\,dx$
\end_inset


\end_layout

\begin_layout Section
The laws of total probability and total expectation
\end_layout

\begin_layout Subsection
Law of total probability : 
\end_layout

\begin_layout Standard
Let X,Y be random variables with some join discrete distribution or continuous
 distribution.
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
(I) If discrete 
\begin_inset Formula $P_{Y}(y)=\sum P_{Y|X=x}(y|x)*P_{X}(x)=\sum P(X=x,Y=y)$
\end_inset

 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
(II) If continuous :
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $F_{y}(y)=\int f_{Y|X}(y|x)*f_{X}(x)\,dx$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
(I') 
\begin_inset Formula $F_{Y}(y)=P(Y\leq y)=\sum P_{y/X=x}(y\leq y|x)*P_{X}(x)=\sum F_{y/X=x}(y|x)*f_{X}(x)\,dx$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 where 
\begin_inset Formula $\sum F_{y/X=x}(y|x)=p_{Y/X=x}(zx)z\,:\,z\leq y$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
(II')
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $F_{Y}(y)=\intop p(y\leq y|X=x)*f_{X}(x)\,dx$
\end_inset


\end_layout

\begin_layout Subsection
Law of total expectation and total variance
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(Y)=E_{X}\left[E_{Y|X}\left(Y|X\right)\right]
\]

\end_inset


\end_layout

\begin_layout Paragraph
Note:
\end_layout

\begin_layout Standard
How do we think of 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

 ? 
\end_layout

\begin_layout Standard
We have not define this since the conditioning 
\begin_inset Quotes eld
\end_inset

things
\begin_inset Quotes erd
\end_inset

 is itself a 
\emph on
random variable
\emph default
 (we only define 
\begin_inset Formula $E\left(Y|X=x\right)$
\end_inset

).
\begin_inset Newline newline
\end_inset

In fact 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

 is itself a random variable.
 For each value of 
\begin_inset Formula $X$
\end_inset

 we'll get a different value of 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

.
\begin_inset Newline newline
\end_inset

Although in more advanced probabilities 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

 can be define under very general conditions.
 We can give a working way of thinking of 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

 under slightly stranger conditions:
\end_layout

\begin_layout Enumerate
Define 
\begin_inset Formula $E\left(Y|X=x\right)$
\end_inset

 as some 
\begin_inset Formula $g(x)$
\end_inset


\end_layout

\begin_layout Enumerate
Define 
\begin_inset Formula $E\left(Y|X\right)$
\end_inset

to be 
\begin_inset Formula $g(X)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g(X)$
\end_inset

 is of course a random variable as 
\begin_inset Formula $X$
\end_inset

 is one.
\end_layout

\begin_layout Standard
We extend the Law of total expectation to a 
\emph on
law of total variance
\emph default
: 
\begin_inset Newline newline
\end_inset

if 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 have some distribution then we can write 
\begin_inset Formula 
\[
\mbox{Var}(Y)=E_{X}\left[\mbox{Var}\left(Y|X\right)\right]+\mbox{Var}_{X}\left[E\left(Y|X\right)\right]
\]

\end_inset


\end_layout

\begin_layout Subsection
Application
\end_layout

\begin_layout Paragraph
Ex: 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{1},X_{1}$
\end_inset

be identically distributed random variable with common mean 
\begin_inset Formula $E(X)=\mu$
\end_inset

 let 
\begin_inset Formula $N$
\end_inset

 be a non-negative integer valued r.v, independent of 
\begin_inset Formula $X_{1,}X_{2},\ldots$
\end_inset

 .
 Then 
\begin_inset Formula $E\left[\sum_{i=1}^{N}X_{i}\right]=E(X)E(N)=E(N)\mu$
\end_inset


\end_layout

\begin_layout Paragraph
Note:
\end_layout

\begin_layout Standard
We cannot simply write 
\begin_inset Formula $E\left[\sum_{i=1}^{N}X_{i}\right]=\sum_{i=1}^{N}E\left[X_{i}\right]$
\end_inset

.
 Since the upper limit of summation is random and nothing in probs allow
 us to take the expected value inside when the sum is random 
\end_layout

\begin_layout Paragraph
Proof:
\end_layout

\begin_layout Standard
The presence of 
\begin_inset Formula $\geq2$
\end_inset

 r.v: 
\begin_inset Formula $N$
\end_inset

 and the 
\begin_inset Formula $X_{i}$
\end_inset

 suggest that conditioning one one or more of them may make thing simpler.
 idea: if we condition on 
\begin_inset Formula $N=n$
\end_inset

 then we have a fixed upper limit sum condition and then 
\begin_inset Formula $E\left[\sum_{i=1}^{n}X_{i}\right]=\sum_{i=1}^{n}E\left[X_{i}\right]$
\end_inset

.
\end_layout

\begin_layout Standard
We use law of total expectation.
 Let 
\begin_inset Formula $S_{n}=\sum_{i=1}^{n}X_{i}$
\end_inset

 we have 
\begin_inset Formula $E\left[S_{n}\right]=E_{n}\left[E\left[S_{n}|N\right]\right]$
\end_inset

 and we need 
\begin_inset Formula $E\left[S_{n}|N\right]=\left.E\left[S_{n}|N=n\right]\right|_{n=N}$
\end_inset

.
 now 
\begin_inset Formula 
\begin{eqnarray*}
E\left[S_{n}|N=n\right] & = & E\left[\sum_{i=1}^{n}X_{i}|N=n\right]\\
 & = & E\left[\sum_{i=1}^{n}X_{i}\right]\\
 & = & \sum_{i=1}^{n}E\left[X_{i}\right]\\
 & = & n\mu
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
since 
\begin_inset Formula $N$
\end_inset

 is independent with all 
\begin_inset Formula $X_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So 
\begin_inset Formula $E\left[S_{n}|N\right]=\left.n\mu\right|_{n=N}=n\mu$
\end_inset

.
 Finally 
\begin_inset Formula $E\left[S_{N}\right]=E\left[N\mu\right]=\mu E\left[N\right]$
\end_inset


\end_layout

\begin_layout Paragraph*
Warning:
\end_layout

\begin_layout Standard
when you condition, retain the conditioning 
\begin_inset Quotes eld
\end_inset

event
\begin_inset Quotes erd
\end_inset

 until you've decide that it can be removed.
 In the above 
\begin_inset Formula $g(n)=E\left[S_{N}|N=n\right]$
\end_inset

 so 
\begin_inset Formula $g(N)=E\left[S_{N}|N\right]$
\end_inset


\end_layout

\begin_layout Subsection
Wald's identity
\end_layout

\begin_layout Standard
the following extension is important since it allows us to remove the assumption
 that 
\begin_inset Formula $N$
\end_inset

 is independent of 
\begin_inset Formula $X_{1,}X_{2},\ldots$
\end_inset

 its called 
\emph on
Wald's identity.

\emph default
 It has various form, the simplest one:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{1,}X_{2},\ldots$
\end_inset

 be identically distributed with 
\begin_inset Formula $E(X)=\mu$
\end_inset

 let be 
\begin_inset Formula $N$
\end_inset

 a 
\emph on
stopping rule, 
\emph default
that is the decision to stop summing at 
\begin_inset Formula $N=n$
\end_inset

.
 It depend only on 
\begin_inset Formula $X_{1,}X_{2},\ldots,X_{n}$
\end_inset

and not on any 
\begin_inset Formula $X_{i},\,i>n$
\end_inset

.
 Remarkably we still has 
\begin_inset Formula 
\[
E\left[\sum_{i=1}^{N}X_{i}\right]=E(N)E(X)=E(N)\mu
\]

\end_inset


\end_layout

\begin_layout Standard
To clarify what is a stopping rule, 2 example, one where 
\begin_inset Formula $N$
\end_inset

 is one, one where not
\end_layout

\begin_layout Subparagraph
Ex1
\end_layout

\begin_layout Standard
Stop summing at 
\begin_inset Formula $N=n$
\end_inset

 if and only if 
\begin_inset Formula $\sum_{i=1}^{n-1}X_{i}<10$
\end_inset

 and 
\begin_inset Formula $\sum_{i=1}^{n}X_{i}\geq10$
\end_inset

.
 Stop summing at 
\begin_inset Formula $n$
\end_inset

 depend only of 
\begin_inset Formula $X_{1,}X_{2},\ldots,X_{n}$
\end_inset


\end_layout

\begin_layout Subparagraph
Ex2
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Example where 
\begin_inset Formula $N$
\end_inset

 won't be the stopping rule:
\end_layout

\begin_layout Standard
Let 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $X_{1,}X_{2},\ldots$
\end_inset

 denote the of cracks fond in a successive weeks in an aircraft component.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $S_{n}=\sum_{i=1}^{n}X_{i}$
\end_inset

 = cumulative number of cracks up to the random week, N.
 Now suppose N is defined as follows: 
\begin_inset Formula $N=n$
\end_inset

, if 
\begin_inset Formula $0$
\end_inset

 new cracks occurs in week 
\begin_inset Formula $n+1$
\end_inset

.
 With this stopping rule, the decision to stop adding the number of cracks
 at month n depends o,n what happens after week n.
 Thus n is not a stopping rule.
 
\end_layout

\begin_layout Section
Probability Generating Function : 
\end_layout

\begin_layout Standard
The following 
\begin_inset Quotes eld
\end_inset

generating function
\begin_inset Quotes erd
\end_inset

 plays a role similar to moment generating function, but it's definition
 is restricted to non-negative integer valued r.v.s, whose support is on {0,1,2..}.
\end_layout

\begin_layout Paragraph
Definition 
\end_layout

\begin_layout Standard
Let X be a discrete r.v.
 with support on {0,1,2..}.
 The probability generating function (pgf) is defined as follows: 
\begin_inset Formula 
\[
\Phi_{X}(z)=\sum_{x=0}^{\infty}z^{x}p_{x}(x)=\sum_{x=0}^{\infty}z^{x}P\left[X=x\right]
\]

\end_inset

 for 
\begin_inset Formula $|z|\leq1$
\end_inset


\end_layout

\begin_layout Standard
Notes: 
\end_layout

\begin_layout Enumerate

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\Phi_{X}(z)$
\end_inset

 is a power series in z which converges for 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
|z|
\begin_inset Formula $\leq1$
\end_inset


\end_layout

\begin_layout Enumerate

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\Phi_{X}(1)=1$
\end_inset


\end_layout

\begin_layout Enumerate
Reason for the name : Given 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Phi_{X}(z)$
\end_inset

 one can generate or recover 
\begin_inset Formula $p_{x}(x)$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
 That is there is a one to one correspondence between a pgf and its distribution.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Newline newline
\end_inset

Proof: Since 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Phi_{X}(z)$
\end_inset

 is a power series in z it is uniformly convergent for 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $|z|<1$
\end_inset

.
 Hence 
\begin_inset Formula $\Phi'_{x}(z)$
\end_inset

 exists for such z and 
\begin_inset Formula $\Phi'_{x}(z)=\frac{d}{dz}\sum_{0}^{\infty}p_{x}(x)=\sum_{0}^{\infty}xz^{x-1}p_{x}(x)=\sum_{1}^{\infty}xz^{x-1}$
\end_inset

 
\begin_inset Formula $\Phi_{x}'(0)=p_{x}(1)$
\end_inset


\begin_inset Newline newline
\end_inset

In a similar fashion, by differentiating successively, setting z=0, we get
 
\begin_inset Formula $\Phi_{x/2!}^{"}(0)=\frac{p_{x}(z)}{z!}$
\end_inset

 to give 
\begin_inset Formula $p_{x}(x)$
\end_inset

=
\begin_inset Formula $\Phi_{X}^{x}(0)/x!$
\end_inset

 or in a more familiar notation : 
\begin_inset Formula $P_{X}(k)$
\end_inset

= 
\begin_inset Formula $\Phi_{X}^{k}(0)/k!,$
\end_inset

 for k=1..
 with 
\begin_inset Formula $\Phi_{X}^{0}(0)=p_{X}(0)=\Phi_{X}(0)$
\end_inset


\end_layout

\begin_layout Enumerate
By setting 
\begin_inset Formula $z=e^{t}$
\end_inset

 we obtain the mgf 
\begin_inset Formula $\sum_{x}e^{tx}p_{x}(x)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\Phi_{X}(z)=E[z^{X}]$
\end_inset


\end_layout

\begin_layout Enumerate
It then follows from 5 that if 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $X_{1,}X_{2},\ldots,X_{n}$
\end_inset

 are independents r.v.s, then 
\begin_inset Formula $\Phi_{\sum_{i=1}^{n}}(z)=E[z^{\sum_{1}^{n}Xi}]=E[\prod_{1}^{n}z^{Xi}]=\prod_{i=1}^{n}E[z^{Xi}]$
\end_inset

=
\begin_inset Formula $\prod_{i=1}^{n}\Phi_{xi}[z]$
\end_inset

 further if the Xiw are identically distributed then 
\begin_inset Formula $\Phi_{\sum_{i=1}^{n}}(z):[\Phi_{x}(z)]^{n}$
\end_inset


\end_layout

\begin_layout Chapter
Stochastic processes themselves
\end_layout

\begin_layout Section
Definition 
\end_layout

\begin_layout Standard
A stochastic process indexed by an index set 
\begin_inset Formula $T$
\end_inset

 is a family of random variables, denoted by 
\begin_inset Formula $\left\{ X{}_{t},\,t\in T\right\} $
\end_inset

 such for each 
\begin_inset Formula $t\in T$
\end_inset

, 
\begin_inset Formula $X{}_{t}$
\end_inset

 is a random variable.
\end_layout

\begin_layout Paragraph
Notes
\end_layout

\begin_layout Enumerate
For each 
\begin_inset Formula $t\in T$
\end_inset

, 
\begin_inset Formula $X{}_{t}$
\end_inset

 is a r.v.
 means 
\begin_inset Formula $X{}_{t}=X{}_{t}(\omega)$
\end_inset

 is a function of 
\begin_inset Formula $\omega\in S,$
\end_inset

 the sample maps of the possible outcomes of 
\begin_inset Formula $X{}_{t}$
\end_inset

 .
 That is for each t, 
\begin_inset Formula $X{}_{t}$
\end_inset

 had a probability distribution that is specified by 
\begin_inset Formula $F_{X{}_{t}}(.)$
\end_inset

its cdf.
 
\end_layout

\begin_layout Enumerate
For each fixed 
\begin_inset Formula $\omega,$
\end_inset

 
\begin_inset Formula $X{}_{t}$
\end_inset

 is a function of 
\begin_inset Formula $t\in T.$
\end_inset

(the idkr set).
 We call this function of t (for fixed 
\begin_inset Formula $\omega\epsilon S$
\end_inset

) a trajectory or sample path of stochastic process.
 We may depict the situation as follows.
 
\end_layout

\begin_layout Enumerate
How is a stochastic process specified? Recall that if X is a r.v.
 it is completely determined or specified once you have specified c.d.f 
\begin_inset Formula $F_{X}$
\end_inset

.
 In the case of stochastic process it turns out that it is uniquely specified
 once you have specified 
\begin_inset Formula $F_{Xt1},$
\end_inset


\begin_inset Formula $F_{Xt2},$
\end_inset

..., 
\begin_inset Formula $F_{Xtn}$
\end_inset

 for all the collections of the r.v.s 
\begin_inset Formula $X_{t1},$
\end_inset


\begin_inset Formula $X_{t2},..,X_{tn}$
\end_inset

for all 
\begin_inset Formula $t1,t2,..,tn\in T$
\end_inset

, and all 
\begin_inset Formula $n$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Notes:
\end_layout

\begin_layout Standard
we can view stochastic process as follow, since 
\begin_inset Formula $\omega\in S$
\end_inset

 is unknown in advance, each projectors in unknown in advance of our experiment.
 Therefore, we can regard a stochastic process as a random function.
 We are sitting in a function space.
 Each point in this space is a function.
 Question that we may ask one 
\begin_inset Quotes eld
\end_inset

What is the probability that this function will fall in some set in this
 function space?
\end_layout

\begin_layout Standard
Extensen theorem is that the probabilities of all the event in this function
 space is uniquely determined by the probabilities specified by the finite
 themselves c.d.f.S.
\end_layout

\begin_layout Standard
Examples stochastic process:
\end_layout

\begin_layout Enumerate
Trivially any single r.v., 
\begin_inset Formula $X$
\end_inset

 is a stochastic process - the family r.v.
\end_layout

\begin_layout Enumerate
the sequence of random variable 
\begin_inset Formula $X_{1},X_{2},X_{3}$
\end_inset

...
\end_layout

\begin_layout Standard
recall knowing 
\begin_inset Formula $P\left[X_{t1}\leq x_{1},\ldots,X_{tn}\leq X_{n}\right]=F_{X_{t1},\ldots,X_{tn}}^{(x_{1},\ldots x_{n})}\,\forall ti\forall n\forall-\infty<x_{i}<\infty$
\end_inset

 gives the unique probabilities 
\begin_inset Formula $P\left[\left\{ X_{t}\in B,t\in T'\right\} \right]$
\end_inset

 (notes: this is useless)
\end_layout

\begin_layout Paragraph
Note:
\end_layout

\begin_layout Standard
The join finite dimensional distribution are uniquely determined in the
 case of a sequence of i.i.d r.v.s by the marginal distribution 
\begin_inset Formula $F_{X}(x)$
\end_inset

 of any member of the sequence.
 : 
\begin_inset Formula $F_{X_{t1},\ldots,X_{tn}}^{(x_{1},\ldots x_{n})}=\prod_{i=1}^{n}F_{X}(x_{i})$
\end_inset


\end_layout

\begin_layout Standard
Such sequences are not really the subject of study in stochastic processes
 because of the assumption of independence
\end_layout

\begin_layout Section
Some non trivial example of stochastic processes
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ x_{t},\,t\in D\right\} $
\end_inset

where 
\begin_inset Formula $X_{t}$
\end_inset

 si the price of e certain stock during day 
\begin_inset Formula $D$
\end_inset

.
 before the stock market opens.
 the price over the day are uncertain.
 the trajectory of 
\begin_inset Formula $X_{t}$
\end_inset

 will typically fluctuate and the 
\begin_inset Formula $X_{i}$
\end_inset

's will be dependent.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ X_{t},\,i\in\left\{ 1,2,\ldots\right\} \right\} $
\end_inset

 where 
\begin_inset Formula $X_{t}$
\end_inset

 denote the number of bacteria on e petri dish at minute 
\begin_inset Formula $t$
\end_inset

 from the time they start dividing
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ X_{t},\,i\in\left\{ 1,2,\ldots\right\} \right\} $
\end_inset

 where 
\begin_inset Formula $X_{t}$
\end_inset

 is the height of a dam above level 
\begin_inset Formula $L$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

 
\end_layout

\begin_layout Enumerate
if 
\begin_inset Formula $\left\{ X_{1},X_{2},\ldots\right\} $
\end_inset

is a sequence of i.i.d r.v.s, let 
\begin_inset Formula $S_{n}=\sum_{i=1}^{n}X_{i}$
\end_inset

 then 
\begin_inset Formula $\left\{ S_{n},\,n=1,2,\ldots\right\} $
\end_inset

 is a stochastic process and is called a 
\emph on
random walk.
\begin_inset Newline newline
\end_inset


\emph default
Note: while 
\begin_inset Formula $X_{i}$
\end_inset

s are independent, the 
\begin_inset Formula $S_{n}$
\end_inset

 are highly dependent
\end_layout

\begin_layout Section
Jargon
\end_layout

\begin_layout Enumerate
if index set is discrete we refer to a 
\emph on
discrete parameter
\emph default
 stochastic process
\begin_inset Newline newline
\end_inset

If continuous (
\begin_inset Formula $T$
\end_inset

 uncountable) we refer to a 
\emph on
continuous parameter
\emph default
 stochastic process
\end_layout

\begin_layout Enumerate
If the set of possible value of 
\begin_inset Formula $X_{t}$
\end_inset

 countable (discrete) we refer to a 
\emph on
discrete state space
\begin_inset Newline newline
\end_inset


\emph default
If uncountable we refer to a 
\emph on
continuous state space
\end_layout

\begin_layout Chapter
Branching Processes
\end_layout

\begin_layout Standard
We will begin by formally defining it, and then mention some application
\end_layout

\begin_layout Section
Definition
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left\{ X_{n},n=0,1,2,\ldots\right\} $
\end_inset

 be a stochastic process of the following properties
\end_layout

\begin_layout Enumerate
\begin_inset Formula $X_{0}=1$
\end_inset


\end_layout

\begin_layout Enumerate
the probability that this individual (
\begin_inset Formula $X_{0})$
\end_inset

 gives rise to 
\begin_inset Formula $j$
\end_inset

 individuals at the next generation is 
\begin_inset Formula $p_{j}$
\end_inset

, for 
\begin_inset Formula $j=0,1,2,\ldots$
\end_inset


\begin_inset Newline newline
\end_inset

i.e 
\begin_inset Formula $P\left[X_{1}=j\,|\,X_{0}=1\right]=p_{j}\,\forall j$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Each
\emph default
 individual in the 1
\begin_inset script superscript

\begin_layout Plain Layout
st 
\end_layout

\end_inset

generation gives rises to 
\begin_inset Formula $j$
\end_inset

 new individuals in the 2
\begin_inset script superscript

\begin_layout Plain Layout
nd
\end_layout

\end_inset

generation with probability 
\begin_inset Formula $p_{j}$
\end_inset

, for 
\begin_inset Formula $j=0,1,2,\ldots$
\end_inset

.
 Independently of all other individuals in this generation and of the generation
 number (
\begin_inset Formula $n$
\end_inset

), and so on for subsequence generations
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{n}$
\end_inset

 be the total size of the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

generation (not the cumulative sum over generation).
 Then 
\begin_inset Formula $\left\{ X_{n},n=0,1,2,\ldots\right\} $
\end_inset

is called a 
\emph on
branching process
\emph default
 (or Galton-Watson branching process)
\end_layout

\begin_layout Paragraph
Example:
\end_layout

\begin_layout Itemize
Physics: nuclear reaction
\end_layout

\begin_layout Itemize
Biology: occurrence of mutant gene over generation, survival of family name
\end_layout

\begin_layout Section
Question we shall address
\end_layout

\begin_layout Enumerate
what are the probability of eventual extinction of the population ?
\end_layout

\begin_layout Enumerate
What are then expected population size of the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

generation ? The variance ?
\end_layout

\begin_layout Standard
To answers 1.
 we shall need to work quite hard and we end up with an interesting, perhaps
 unexpected, result.
 
\end_layout

\begin_layout Standard
Even though we can view 
\begin_inset Formula $\left\{ X_{n},n=0,1,2,\ldots\right\} $
\end_inset

 as a Markov chain, we shall answers these questions without reference to
 them by using conditional expectation and probability generating function.
 
\end_layout

\begin_layout Standard
The details are important !!
\end_layout

\begin_layout Section
Answers:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $p_{0}(n)$
\end_inset

 denote the probability that there are no individuals in the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

 generation.
 We want to find 
\begin_inset Formula 
\begin{eqnarray}
P\left[\bigcup_{k=1}^{\infty}\left\{ X_{k}=0\right\} \right] & = & P\left[\lim_{n\rightarrow\infty}\bigcup_{k=1}^{n}\left\{ X_{k}=0\right\} \right]\nonumber \\
 & = & \lim_{n\rightarrow\infty}P\left[\bigcup_{k=1}^{n}\left\{ X_{k}=0\right\} \right]\label{eq:lim}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
Now notes that 
\begin_inset Formula $X_{n}=0\Rightarrow X_{n+1}=0$
\end_inset

 .
 i.e becomes 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lim"

\end_inset

 
\begin_inset Formula 
\[
\lim_{n\rightarrow\infty}P\left[X_{n}=0\right]=\lim_{n\rightarrow\infty}p_{0}(n)
\]

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\Phi_{X_{n}}(z)$
\end_inset

 be the p.g.f of 
\begin_inset Formula $X_{n}$
\end_inset

, for any p.g.f we have 
\begin_inset Formula $\Phi(0)=p_{0}\Rightarrow p_{0}(n)=\Phi_{X_{n}}(0)$
\end_inset

.
\end_layout

\begin_layout Standard
Thus it seems that the discussion reduce to one of p.g.f.s.
 this is, indeed, the case.
 Let 
\begin_inset Formula $\Phi(z)$
\end_inset

 be the p.g.f of 
\begin_inset Formula $X_{1}$
\end_inset

, which of course is the p.g.f of the r.v that gives the number that arise
 from any single of individuals in
\emph on
 any
\emph default
 generation
\end_layout

\begin_layout Paragraph
Lemma:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\Phi_{X_{n}}(z) & = & \Phi_{X_{n-1}}\left(\Phi(z)\right)\label{eq:11}\\
 & = & \Phi\left(\Phi_{X_{n-1}}(z)\right)\;\forall n\geq1\label{eq:12}\\
\nonumber 
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
The idea in proving both 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset

 is that in each case we can write 
\begin_inset Formula $X_{n}$
\end_inset

 as a random sum of random variable.
 with this observation we shall condition the upper limit of summation.
\end_layout

\begin_layout Subsection
Proof of the lemma 
\end_layout

\begin_layout Subsubsection
Proof of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset


\end_layout

\begin_layout Standard
Observe that if we let 
\begin_inset Formula $Y_{i}$
\end_inset

 be the number of 
\begin_inset Quotes eld
\end_inset

offspring
\begin_inset Quotes erd
\end_inset

 from parent 
\begin_inset Formula $i$
\end_inset

 in the (n-1)
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

generation, then 
\begin_inset Formula $X_{n}=\sum_{i=1}^{X_{n-1}}Y_{i}$
\end_inset


\end_layout

\begin_layout Subparagraph
Note:
\end_layout

\begin_layout Standard
that we haven't not attached a subscript 
\begin_inset Formula $n-1$
\end_inset

 to 
\begin_inset Formula $Y_{i}$
\end_inset

 (i.e 
\begin_inset Formula $Y_{i,n-1}$
\end_inset

) since the distribution of 
\begin_inset Formula $Y_{i,n-1}$
\end_inset

 is the same for all 
\begin_inset Formula $n$
\end_inset

 by the assumption of branching processes.
 
\end_layout

\begin_layout Standard
We now need 
\begin_inset Formula $\Phi_{X_{n}}(z)=\Phi_{\sum_{i=1}^{X_{n-1}}Y_{i}}(z)$
\end_inset

.
 Looks bad, but observe that if we condition on 
\begin_inset Formula $X_{n-1}=k$
\end_inset

, than we would be dealing with 
\begin_inset Formula $\Phi_{\sum_{i=1}^{k}Y_{i}}(z)$
\end_inset

 the p.g.f of a fixed sum of i.i.d r.v.s.
 The 
\begin_inset Formula $Y_{i}$
\end_inset

's are independent and identically distributed by assumption.
\end_layout

\begin_layout Standard
Thus use 
\begin_inset Formula $\Phi_{X_{n}}(z)=E\left[z^{X_{n}}\right]=E_{X_{n-1}}\left[E\left[z^{\sum_{i=1}^{X_{n-1}}Y_{i}}|X_{n-1}\right]\right]$
\end_inset


\end_layout

\begin_layout Standard
now: 
\begin_inset Formula 
\begin{eqnarray*}
E\left[z^{\sum_{i=1}^{X_{n-1}}Y_{i}}|X_{n-1}=k\right] & = & E\left[z^{\sum_{i=1}^{k}Y_{i}}|X_{n-1}=k\right]\\
 & = & E\left[z^{\sum_{i=1}^{k}Y_{i}}\right]\mbox{indep of \ensuremath{\left\{ X_{n-1}=k\right\} }and \ensuremath{\left\{ Y_{1},\ldots,Y_{k}\right\} }}\\
 & = & \Phi_{\sum_{i=1}^{k}Y_{i}}(z)\\
 & = & \left[\Phi_{X_{1}}(z)\right]^{k}=\left[\Phi(z)\right]^{k}
\end{eqnarray*}

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Note that's because
\begin_inset Formula $Y_{i}$
\end_inset

 as the same distribution as 
\begin_inset Formula $X_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
Finally 
\begin_inset Formula $E_{X_{n-1}}\left[\left(\Phi(z)\right)^{X_{n-1}}\right]=\Phi_{X_{n-1}}\left(\Phi(z)\right)$
\end_inset

 (by the definition of 
\begin_inset Formula $\Phi_{X_{n-1}}$
\end_inset

).
\end_layout

\begin_layout Standard
this proves 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset


\end_layout

\begin_layout Subsubsection
Proof of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset


\end_layout

\begin_layout Standard
to get 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset

 we we argue slightly differently.
 The no in the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

generation is the sum The sum of the number that come from the sub generation
 of each 
\begin_inset Quotes eld
\end_inset

parent
\begin_inset Quotes erd
\end_inset

 in the first generation.
\end_layout

\begin_layout Standard
The number that end up 
\begin_inset Formula $(n-1)$
\end_inset

 generation after each parent in the 1
\begin_inset script superscript

\begin_layout Plain Layout
st
\end_layout

\end_inset

are i.i.d r.v.s, Call them 
\begin_inset Formula $X_{n-1,i}\,i=1,\ldots,X_{1}$
\end_inset

.
 Thus 
\begin_inset Formula $X_{n}=\sum_{i=1}^{X_{1}}X_{n-1,i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Using the same type of argument, as for 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset

 (Conditioning on 
\begin_inset Formula $X_{1}$
\end_inset

 this time), we get 
\begin_inset Formula 
\begin{eqnarray*}
E\left[z^{X_{n}}\right] & = & E_{X_{1}}\left[E\left[z^{\sum_{i=1}^{X_{1}}X_{n-1,i}}|X_{i}\right]\right]\\
 & = & \Phi_{X_{1}}\left[\Phi_{X_{n-1}}(z)\right]=\Phi\left[\Phi_{X_{n-1}}(z)\right]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
These equality have been established for all 
\begin_inset Formula $n\geq1$
\end_inset

 and are easily seen (do this) to be true for 
\begin_inset Formula $n=1$
\end_inset


\end_layout

\begin_layout Subsection
Answer of 1.
\end_layout

\begin_layout Standard
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset

 form the basis for the completion of the analysis :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lim_{n\rightarrow\infty}\Phi_{X_{n}}(0)=\lim_{n\rightarrow\infty}\Phi_{X_{n-1}}\left(\Phi(0)\right)=\lim_{n\rightarrow\infty}\Phi\left(\Phi_{X_{n-1}}(0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
We still examine 
\begin_inset Formula $\lim_{n\rightarrow\infty}\Phi_{X_{n}}(0)$
\end_inset

, but first we need to justify the existence of this limit.
\end_layout

\begin_layout Paragraph
Note:
\end_layout

\begin_layout Standard
that 
\begin_inset Formula $\Phi_{X_{n}}(z)$
\end_inset

 is bounded for all 
\begin_inset Formula $|z|\leq1$
\end_inset

 and for all 
\begin_inset Formula $n$
\end_inset

 
\begin_inset Formula $\Phi_{n}(z)\leq\sum_{k=0}^{\infty}|z|^{k}P\left[X_{n}=k\right]\leq\sum_{k}P\left[X_{n}=k\right]=1$
\end_inset

.
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\Phi_{X_{n}}(0)=P\left[X_{n}=0\right]$
\end_inset

 and since 
\begin_inset Formula $\left\{ X_{n}=0\right\} \subset\left\{ X_{n+1}=0\right\} $
\end_inset

 then
\begin_inset Formula $P\left[X_{n}=0\right]\leq P\left[X_{n+1}=0\right]$
\end_inset


\end_layout

\begin_layout Standard
And so
\begin_inset Formula $\left\{ \Phi_{X_{n}}(0)\right\} $
\end_inset

is a bounded non decreasing sequence and thus 
\begin_inset Formula $\lim_{n\rightarrow\infty}\Phi_{X_{n}}(0)$
\end_inset

 exist 
\begin_inset Formula $\eta$
\end_inset

.
\end_layout

\begin_layout Paragraph
Recall:
\end_layout

\begin_layout Standard
\begin_inset Formula $\Phi_{X_{n}}(z)=\Phi_{X_{n-1}}\left(\Phi(z)\right)=\Phi\left(\Phi_{X_{n-1}}(z)\right)\;\forall n\geq1$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset

 then 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset


\end_layout

\begin_layout Standard
And so using using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset

 
\begin_inset Formula $\lim_{n\rightarrow\infty}\Phi_{X_{n}}(0)=\lim_{n\rightarrow\infty}\Phi\left(\Phi_{X_{n-1}}(0)\right)=\Phi\left(\lim_{n\rightarrow\infty}\Phi_{X_{n-1}}(0)\right)$
\end_inset

 (
\begin_inset Formula $\Phi$
\end_inset

 is continuous).
 this implies 
\begin_inset Formula $\eta=\Phi(\eta)$
\end_inset

 so the limit must satisfy this properties.
\end_layout

\begin_layout Standard
We need to examine the root of 
\begin_inset Formula $z_{0}=\Phi(z_{0})$
\end_inset

.
\end_layout

\begin_layout Standard
It's easy to see that 
\begin_inset Formula $\Phi(z)$
\end_inset

 is convex in 
\begin_inset Formula $z$
\end_inset

.
 so differentiate twice.
\end_layout

\begin_layout Standard
For now on, assume that 
\begin_inset Formula $P\left[X_{1}=0\right]>0$
\end_inset

, if not the probability of extinction will be 
\begin_inset Formula $0$
\end_inset

.
 We have the following pictures (non)
\end_layout

\begin_layout Standard
We see that 
\begin_inset Formula $z=1$
\end_inset

 is a root since 
\begin_inset Formula $\Phi_{X_{n}}(1)=1$
\end_inset

.
 We see that there's 2 possible roots.
\end_layout

\begin_layout Standard
We shall see that 
\begin_inset Formula $\eta$
\end_inset

 is the smallest possible root.
 
\end_layout

\begin_layout Standard
We have 
\begin_inset Formula $p_{0}(1)=\Phi(0)\leq\Phi(z_{0})=z_{0}$
\end_inset

 for any possible root 
\begin_inset Formula $z_{0}$
\end_inset

 of 
\begin_inset Formula $\Phi(z)=z$
\end_inset

.
 Using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:11"

\end_inset


\begin_inset Formula $p_{0}(z)=\Phi_{X_{2-1=1}}\left(\Phi(0)\right)=\Phi(z_{0})=z_{0}$
\end_inset

.
 and so on for all 
\begin_inset Formula $p_{0}(n)$
\end_inset

 
\end_layout

\begin_layout Standard
So: 
\begin_inset Formula $\lim_{n\rightarrow\infty}p_{0}(n)=\eta\leq z_{0}$
\end_inset

.
 And so 
\begin_inset Formula $\eta$
\end_inset

 is the smallest positive root of 
\begin_inset Formula $\Phi(z)=z$
\end_inset

.
\end_layout

\begin_layout Paragraph
Question:
\end_layout

\begin_layout Standard
Under what circumstance is there only one positive root ? that is, when
 will the only root be 
\begin_inset Formula $\eta=1$
\end_inset

.
\end_layout

\begin_layout Standard
From the pictures we see that there's exactly one root (at 
\begin_inset Formula $z=1$
\end_inset

) if and only if 
\begin_inset Formula $\Phi'(1)\leq1$
\end_inset

.
 But 
\begin_inset Formula $\Phi'(1)=\mu=E\left(X_{1}\right)$
\end_inset


\end_layout

\begin_layout Paragraph
So:
\end_layout

\begin_layout Standard
the branching process will end in extinction if 
\begin_inset Formula $\mu\leq1$
\end_inset

 we will have a probability of extinction 
\begin_inset Formula $\eta>0$
\end_inset

 if 
\begin_inset Formula $\mu>1$
\end_inset

 (i.e there's is pos probability of non-extinction).
 note that is never the case that 
\begin_inset Formula $\eta=0$
\end_inset

 : 
\begin_inset Formula $\mu>1\Rightarrow\eta>0\wedge\eta<1$
\end_inset


\end_layout

\begin_layout Paragraph
Notes:
\end_layout

\begin_layout Enumerate
In practice if a population is to become extinct, this happens quickly
\end_layout

\begin_layout Enumerate
if we start with 
\begin_inset Formula $a$
\end_inset

 individuals (instead of 
\begin_inset Formula $1$
\end_inset

) then the probability of extinction of 
\emph on
all
\emph default
 descendant is 
\begin_inset Formula $\eta^{a}$
\end_inset

 (since the lines develops independently)
\begin_inset Newline newline
\end_inset

thus, with 
\begin_inset Formula $a$
\end_inset

 to star with, the probability of non extinction is 
\begin_inset Formula $1-\eta^{a}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
This has interesting application in nuclear fission (in nuclear chain reaction)
 because obviously we want the reaction (branching process) to die out
\end_layout

\begin_layout Standard
Even if 
\begin_inset Formula $\eta$
\end_inset

 is large, 
\begin_inset Formula $\eta^{a}$
\end_inset

 will be small if 
\begin_inset Formula $a$
\end_inset

 (the 
\begin_inset Quotes eld
\end_inset

critical mass
\begin_inset Quotes erd
\end_inset

) is taken to be 
\emph on
very
\emph default
 large, in this case 
\begin_inset Formula $\eta^{a}$
\end_inset

 will be small and the probability that the nuclear reaction will be maintained
 
\begin_inset Formula $1-\eta^{a}$
\end_inset

 will be large
\end_layout

\end_deeper
\begin_layout Enumerate
one extension to the Glaton branching-process is the so called Branching
 process with Random Environment.
 the 
\begin_inset Quotes eld
\end_inset

division probability
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $p_{j}$
\end_inset

 change over time.
 For example, the environment might changing (is it !) leading to different
 reproduction rates
\end_layout

\begin_layout Enumerate
Another generalization is to Multi-type Branching Process.
 Whereby a population is composed of different subtype each with a different
 
\begin_inset Formula $\left\{ p_{j}\right\} $
\end_inset


\end_layout

\begin_layout Subsection
What is 
\begin_inset Formula $E\left(X_{n}\right)$
\end_inset

 and 
\begin_inset Formula $\mbox{Var}\left(X_{n}\right)$
\end_inset

 ? (Answer of 2.)
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\mu_{n}=E\left(X_{n}\right)$
\end_inset

.
 Then 
\begin_inset Formula $\mu_{n}=\Phi'_{X_{n}}(1)$
\end_inset

.
 But we know that 
\begin_inset Formula $\Phi_{X_{n}}(z)=\Phi_{X_{n-1}}\left(\Phi(z)\right)$
\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset


\end_layout

\begin_layout Standard
Then we have 
\begin_inset Formula $\mu_{n}=\Phi'_{X_{n}}(z)=\Phi'(1)\Phi_{X_{n-1}}'(1)$
\end_inset

 (chain rule)
\end_layout

\begin_layout Standard
Which mean that 
\begin_inset Formula $\Phi'_{X_{n}}(z)=\mu_{n}=\mu\Phi'_{X_{n-1}}(1)=\mu\mu_{n-1}$
\end_inset

 which gives immediately 
\begin_inset Formula $\mu_{n}=\mu^{n}$
\end_inset


\end_layout

\begin_layout Standard
Thus is 
\begin_inset Formula $\mu>1$
\end_inset

 the mean population grows geometrically , and if 
\begin_inset Formula $\mu<1$
\end_inset

 it decline very quickly (geometrically)), If 
\begin_inset Formula $\mu=1$
\end_inset

 then the population size is constant (
\begin_inset Formula $=1$
\end_inset

).
\end_layout

\begin_layout Standard
To obtain 
\begin_inset Formula $\mbox{Var}\left(X_{n}\right)$
\end_inset

 we use 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:12"

\end_inset

 once more (see 2) bur argument is more difficult.
 We find: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\mbox{Var}\left(X_{n}\right)=\sigma_{n}^{2} & = & \sigma^{2}\mu^{n-1}\frac{\left[\mu^{n}-1\right]}{\mu-1},\mbox{ if \ensuremath{\mu\neq1}}\\
 & = & n\sigma^{2}\mbox{, if \ensuremath{\mu=1}}
\end{eqnarray*}

\end_inset

Thus 
\begin_inset Formula $\sigma_{n}^{2}$
\end_inset

increase (decrease) geometrically if 
\begin_inset Formula $\mu\neq1$
\end_inset

, possibly explaining why 
\begin_inset Formula $\eta>0$
\end_inset

 even if 
\begin_inset Formula $\mu>1$
\end_inset

: large fluctuation give a chance of falling into the breach of extinction.
\end_layout

\begin_layout Chapter
Markov Chains
\end_layout

\begin_layout Standard
Almost always there is an underlying dependence structure to the stochastic
 processes that we discuss.
 A special type of dependence structure is assumed when we discuss Markov
 chain, this structures assumes the so calls 
\emph on
Markov property
\emph default
 
\end_layout

\begin_layout Standard
To begin, we shall assume that our process
\begin_inset Formula $\left\{ X_{n},\,n=0,1,\ldots\right\} $
\end_inset

 is a discrete parameter countable state space process.
 The state of space of 
\begin_inset Formula $\left\{ X_{n},\,n=0,1,\ldots\right\} $
\end_inset

 could be denoted 
\begin_inset Formula $E_{1,}$
\end_inset


\begin_inset Formula $E_{2}..$
\end_inset

 but for notation simplicity, by, 
\begin_inset Formula $1,2,\ldots$
\end_inset


\end_layout

\begin_layout Section
Definition of a Markov chain
\end_layout

\begin_layout Paragraph
Definition:
\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ X_{n},\,n=0,1,\ldots\right\} $
\end_inset

 is called a (discrete state space) Markov chain if
\end_layout

\begin_layout Standard
\begin_inset Formula $P\left[X_{n+1}=j|X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i\right]=P\left[X_{n+1}=j|X_{n}=i\right]=P_{ij}$
\end_inset

 for all 
\begin_inset Formula $n\geq0$
\end_inset

, and all states 
\begin_inset Formula $i_{0},i_{1},\ldots,i_{n}$
\end_inset


\end_layout

\begin_layout Paragraph
Notes:
\end_layout

\begin_layout Standard
1) 
\begin_inset Formula $P_{ij}$
\end_inset

is called the one step transition probability of the chain.
 It describes the probability of moving from at state 
\begin_inset Formula $i$
\end_inset

 to a state 
\begin_inset Formula $j$
\end_inset

 in one state.
 
\end_layout

\begin_layout Standard
Notice that 
\begin_inset Formula $P_{ij}$
\end_inset

 is assumed not to depend on n.
 
\end_layout

\begin_layout Standard
i.e.
 we should really write 
\begin_inset Formula $P_{ij}^{n}$
\end_inset

.
 Chain for which 
\begin_inset Formula $P_{ij}$
\end_inset

 does not depend on 
\begin_inset Formula $n$
\end_inset

 are called 
\emph on
homogeneous
\emph default
.
 [If depend on n, non-homogeneous].
 We restrict ourselves to homogenous chains.
 
\end_layout

\begin_layout Standard
2) Importantly, the Markov property says that the history is summarized
 in the immediate past.
 
\end_layout

\begin_layout Standard
It does not assert that 
\begin_inset Formula $X_{n+1}$
\end_inset

is independent of 
\begin_inset Formula $X_{0},X_{1},\ldots,X_{n-1}$
\end_inset


\end_layout

\begin_layout Standard
Example: Our branching process is easily seen to be a Markov chain, since
 given the generation size, 
\begin_inset Formula $X_{0},X_{1},..,X_{n-1},X_{n}$
\end_inset

 the distribution of 
\begin_inset Formula $X_{n+1}$
\end_inset

depends only on 
\begin_inset Formula $X_{n}$
\end_inset


\end_layout

\begin_layout Standard
4)The term homogeneous is sometimes called stationary i.e.
 we talk of a stationary Markov Chain.
 
\end_layout

\begin_layout Standard
Reason(to be further clarified later) is that with the assumption of homogeneity
 (stationarity) the join finite dimensional distributions, are invariant
 under shifts in time.
\end_layout

\begin_layout Subparagraph
Example of non-stationary Markov chain:
\end_layout

\begin_layout Standard
A branching process with the number of children from each from each parent
 in a generation, having a distribution that depends on the generation number
 in fertility changes with n.
 
\end_layout

\begin_layout Standard
5) a process that satisfies the Markov property above is called 1st order
 Markov.
 If the conditional probability reduced to what the previous 2 states were,
 we called such a process 2nd order Markov..
 etc.
 
\end_layout

\begin_layout Section
How does all of this work? 
\end_layout

\begin_layout Standard
We wish to model a sequence of dependent r.v.s.
 To do this requires specifying the joint finite dimensional distribution
 - a hard problem.
 However, if we can assume the special dependence structure induced by the
 Markov property then we'l see that the specification of the finite dimensional
 distribution is make much simpler.
 Of course, one has to be satisfied that the Markov property holds.
 There are statistical tests that can be used to test the Markov assumption.
 
\end_layout

\begin_layout Standard
Terminology:
\end_layout

\begin_layout Standard
The one step transmission probabilities are denoted by
\begin_inset Formula $P_{ij}$
\end_inset

.
 The complete set of 
\begin_inset Formula $P_{ij}$
\end_inset

 is displayed in the transition matrix:
\end_layout

\begin_layout Standard
\begin_inset Formula $P=\begin{bmatrix}p_{11} & p_{12} & \cdots\\
p_{21} & p_{22} & \cdots\\
\cdots & \cdots & \ddots
\end{bmatrix}$
\end_inset


\end_layout

\begin_layout Standard
Some 
\begin_inset Formula $P_{ij}$
\end_inset

 may be 0.
 We have immediately that 
\begin_inset Formula $\sum_{j}P_{ij}=1$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 You have to go some-where from state i.
 
\begin_inset Formula $P$
\end_inset

 is called a stochastic matrix - non negative entries sum to one.
 Of course the matrix could be finite corresponding to 
\begin_inset Formula $m$
\end_inset

 states.
 
\end_layout

\begin_layout Standard
Precision: 
\begin_inset Formula $P_{ij}^{(n)}=P\left[X_{n}=j|X_{0}=i\right]$
\end_inset

 = Probs of going from 
\begin_inset Formula $i$
\end_inset

 to 
\begin_inset Formula $j$
\end_inset

 in 
\begin_inset Formula $n$
\end_inset

 steps
\end_layout

\begin_layout Standard
The aim here is to find an expression for 
\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

, or at least a mean of obtaining 
\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

.
 In principle, the way is through what we call the 
\noun on
Chapman-Kolmogorov
\noun default
 equations
\end_layout

\begin_layout Subsection
Theorem:
\end_layout

\begin_layout Standard
let 
\begin_inset Formula $P^{(n)}=\left\{ p_{ij}^{(n)}\right\} $
\end_inset

 be the matrix whose entries are the n-step transition probabilities 
\begin_inset Formula $p_{ij}^{(n)}$
\end_inset

.
 Then 
\begin_inset Formula 
\[
P^{(m+n)}=P^{(m)}P^{(n)}
\]

\end_inset


\end_layout

\begin_layout Standard
a corollary will be 
\begin_inset Formula 
\[
P^{(n)}=P^{n}=\left[\left\{ p_{ij}\right\} \right]^{n}
\]

\end_inset


\end_layout

\begin_layout Subsection
Proof
\end_layout

\begin_layout Paragraph
Theorem proof:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P\left[X_{m+n}=j|X_{0}=i\right] & = & \sum_{k}P\left[X_{m+n},X_{m}=k|X_{0}=I\right]\\
 & = & \sum_{k}\frac{P\left[X_{m+n}=j,\,X_{m}=k,\,X_{0}=i\right]}{P\left[X_{0}=i\right]}\\
 & = & \sum_{k}\frac{P\left[X_{m+n}=j|X_{m}=k,\,X_{0}=i\right]P\left[X_{m}=k|X_{0}=i\right]P\left[X_{0}=i\right]}{P\left[X_{0}=i\right]}\\
 & = & \sum_{k}\underbrace{P\left[X_{m+n}=j|X_{m}=k\right]}_{\mbox{Markov prop}}P\left[X_{m}=k|X_{0}=i\right]\\
 & = & \sum_{k}\underbrace{P_{ik}^{(m)}p_{kj}^{(n)}}_{\mbox{Homogenity }}=P_{ij}^{(m+n)}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Which shows that 
\begin_inset Formula $P_{ij}^{(m+n)}$
\end_inset

 is just the i-j
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

elements of the product of the matrices 
\begin_inset Formula $P^{(m)}$
\end_inset

 and 
\begin_inset Formula $P^{(n)}$
\end_inset

, i.e: 
\begin_inset Formula $P^{(m+n)}=P^{(m)}P^{(n)}$
\end_inset


\end_layout

\begin_layout Paragraph
Corollary proof:
\end_layout

\begin_layout Standard
In particular take 
\begin_inset Formula $m=1,\,n=1,\,\left[n+m=2\right]$
\end_inset

 then 
\begin_inset Formula $P^{(2)}=P.P=P^{2}$
\end_inset

 and then 
\begin_inset Formula $P^{(3)}=P.P^{(2)}=P.P^{2}$
\end_inset

 , etc\SpecialChar \ldots{}
 This can be generalize by induction to 
\begin_inset Formula $P^{(n)}=P^{n}$
\end_inset


\end_layout

\begin_layout Standard
In principle if the chain finite (it has finite many step) we can find 
\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

 by doing successive matrix multiplication.
\end_layout

\begin_layout Standard
If the number of step is infinite then this does not work and we will se
 that w often end up having to approximate 
\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

 for large 
\begin_inset Formula $n$
\end_inset

 by 
\begin_inset Formula $\lim_{n\rightarrow\infty}P_{ij}^{(n)}$
\end_inset

 (Still to come)
\end_layout

\begin_layout Subsection
Some example.
\end_layout

\begin_layout Subsubsection
Example 1
\end_layout

\begin_layout Standard
Consider a communication system which transmit the digits 0 or 1.
 Each digit transmitted must pass through serval stage at each of which
 there's a prob 
\begin_inset Formula $p$
\end_inset

 that the digit will be unchanged when it leaves the stage, let 
\begin_inset Formula $X_{n}$
\end_inset

 the digits the 
\begin_inset Formula $n^{th}$
\end_inset

 stage then 
\begin_inset Formula $\left\{ X_{n},n=0,1,\ldots\right\} $
\end_inset

 is a 2-state Markov chain with 
\begin_inset Formula $P=\left[\begin{array}{cc}
p & 1-p\\
1-p & p
\end{array}\right]$
\end_inset


\end_layout

\begin_layout Subsubsection
Example 2 The simple random Walk
\end_layout

\begin_layout Standard
This is a basic well-studied non-trivial example of a Markov chain that
 is constructed from basic properties easy to imagine.
\end_layout

\begin_layout Standard
Suppose that a particle can jump between the integers (
\begin_inset Formula $\mathbb{Z}$
\end_inset

) on the x-axis according to the following rules
\end_layout

\begin_layout Enumerate
It can move either form it current position (integer) by moving either 1
 step to the left, or 1 step to the right
\end_layout

\begin_layout Enumerate
it moves independently of how many chain it has taken
\end_layout

\begin_layout Enumerate
it move 1 step to right with probability 
\begin_inset Formula $p$
\end_inset

 no matter what is its current position, and 1 step to the left with prob
 
\begin_inset Formula $1-p$
\end_inset


\end_layout

\begin_layout Enumerate
it moves independently of its previous move 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{n}$
\end_inset

 be the position of the particle after 
\begin_inset Formula $n$
\end_inset

 moves.
 we call 
\begin_inset Formula $\left\{ X_{n},\,n=0,1,2,\ldots\right\} $
\end_inset

 the 
\emph on
simple random walk
\emph default
 
\end_layout

\begin_layout Paragraph
Claim:
\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ X_{n},\,n=0,1,2,\ldots\right\} $
\end_inset

 form a Markov chain.
\end_layout

\begin_layout Standard
We begin by writing down the transition matrix 
\begin_inset Formula 
\[
P=\left[\begin{array}{ccccccc}
\ddots & \cdots & \cdots & \cdots & \cdots & \cdots & \vdots\\
\vdots & 0 & p & 0 & 0 & 0 & \vdots\\
\vdots & 1-p & 0 & p & 0 & 0 & \vdots\\
\vdots & 0 & 1-p & 0 & p & 0 & \vdots\\
\cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \ddots
\end{array}\right]
\]

\end_inset

(This matrix is centered on 0).
\end_layout

\begin_layout Standard
Next to show that 
\begin_inset Formula $\left\{ X_{n},\,n=0,1,2,\ldots\right\} $
\end_inset

 is a Markov chain, write 
\begin_inset Formula $X_{n}$
\end_inset

 as 
\begin_inset Formula $X_{n}=\sum_{l=0}^{n}y_{l}$
\end_inset

 where 
\begin_inset Formula $y_{l}$
\end_inset

 are r.v.s such that 
\begin_inset Formula $P\left[y_{l}=+1\right]=p,\,P\left[y_{l}=-1\right]=1-p$
\end_inset

.
 
\end_layout

\begin_layout Standard
These 
\begin_inset Formula $y_{l}$
\end_inset

 are the step sizes, 
\begin_inset Formula $X_{n}$
\end_inset

 is a result of summing the steps to the right plus to the left.
 Now let's check the Markov properties
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P\left[X_{n+1}=j\,|\,X_{0}=0,X_{1}=i_{1},\ldots,X_{n}=i\right] & = & P\left[\sum_{l=0}^{n+1}y_{l}=j\,|\,X_{0}=0,\sum_{l=0}^{1}y_{l}=i_{i},\ldots,\sum_{l=0}^{n}y_{l}=i\right]\\
 & = & P\left[\sum_{l=0}^{n}y_{l}+y_{n+1}=j\,|\,X_{0}=0,\ldots,\sum_{l=0}^{n}y_{l}=i\right]\\
 & = & P\left[\left(i+y_{n+1}\right)=j\,|\,\ldots\right]\\
 & = & P\left[y_{n+1}=j-i\,|\,X_{0}=0,\ldots,\sum_{l=0}^{n}y_{l}=i\right]\\
 & = & P\left[y_{n+1}=j-i\right]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Because in fact because 
\begin_inset Formula $y_{n+1}$
\end_inset

 is independent of all the sums to the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

 by assumption (3).
 But 
\begin_inset Formula $P\left[y_{n+1}=j-i\right]=P\left[\sum_{l=0}^{n+1}y_{l}=j\,|\,\sum_{l=0}^{n}y_{l}=i\right]$
\end_inset

 which establishes the Markov property.
\end_layout

\begin_layout Standard
Further, 
\begin_inset Formula $P\left[y_{n+1}=j-i\right]=\begin{cases}
p & j=i+1\\
1-p & j=i-1\\
0 & \left|j-i\right|>1
\end{cases}$
\end_inset


\end_layout

\begin_layout Subsubsection
Example 3
\end_layout

\begin_layout Standard
Consider a gambler who at each play wins $1 with prob 
\begin_inset Formula $p$
\end_inset

 and loses $1 with prob 
\begin_inset Formula $1-p$
\end_inset

.
 Suppose that the gambler stop playing when she goes broke or attains $
\begin_inset Formula $N$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{n}$
\end_inset

 be the gambler fortune after 
\begin_inset Formula $n$
\end_inset

 games.
 We claim that 
\begin_inset Formula $X_{n},\left\{ n=0,1,\ldots\right\} $
\end_inset

 is a Markov chain with what one known as absorbing state at 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $N$
\end_inset

: once you are at 
\begin_inset Formula $0$
\end_inset

 or 
\begin_inset Formula $N$
\end_inset

 you remain there with prop 
\begin_inset Formula $1$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 You have to go some-where from state 
\begin_inset Formula $i$
\end_inset

.
\end_layout

\begin_layout Section
Communicating states and classification of states
\end_layout

\begin_layout Subsection
Finite dimensional distributions
\end_layout

\begin_layout Standard
\begin_inset Formula $P$
\end_inset

 is called a stochastic matrix - non negative entries sum to one.
 Of course the matrix could be finite corresponding to 
\begin_inset Formula $m$
\end_inset

 states.
 The following theorem says that the knowing 
\begin_inset Formula $P[X_{0}=i]$
\end_inset

 for 
\begin_inset Formula $i=1,2,...$
\end_inset

[the so called initial distribution] and the transition matrix 
\begin_inset Formula $P$
\end_inset

 is sufficient to completely specify the markov chain.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left\{ X_{n},n=0,1..\right\} $
\end_inset

 be a Markov chain.
 Then, its finite dimensional distributions are uniquely determined by 
\begin_inset Formula $\left\{ P[X_{0}=i],i=1,2,..,P\right\} $
\end_inset


\end_layout

\begin_layout Subsubsection*
Proof:
\end_layout

\begin_layout Standard
We must know that we can write the joint distribution of any set 
\begin_inset Formula $X_{n1},X_{n2}....$
\end_inset

 in term of 
\begin_inset Formula $P[X_{0}=i]$
\end_inset

 and a 
\begin_inset Quotes eld
\end_inset

bunch
\begin_inset Quotes erd
\end_inset

 of i-step transition probabilities 
\begin_inset Formula $P_{ij}$
\end_inset


\end_layout

\begin_layout Standard
We convey the idea through a special case: Thus consider 
\begin_inset Formula $P[X_{2}=k,X_{3}=l]$
\end_inset


\end_layout

\begin_layout Standard
Thus 
\begin_inset Formula 
\begin{eqnarray*}
P[X_{2}=k,X_{3}=l] & = & P[X_{3}=l|X_{2}=k]*P[X_{2}=k]\\
 & = & P\ensuremath{_{kl}*\sum_{i,j}P[X_{2}=k\cap X_{0}=i,}\ensuremath{X_{1}=j]}\\
 & = & P_{kl}*\sum P[X_{2}=k|X_{1}=j]*P[X_{i}=j|X_{0}=i]*P[X_{0}=i]\\
 & = & P_{kl}\sum_{i,j}P_{ij}P_{jk}P[X_{0}=i]
\end{eqnarray*}

\end_inset

which is a function only of the i-step transition probs and 
\begin_inset Formula $P[X_{0}=i]$
\end_inset

.
\end_layout

\begin_layout Standard
The idea is simply that to find the probabilities of going from state 
\begin_inset Formula $i$
\end_inset

 to state 
\begin_inset Formula $j$
\end_inset

 in 
\begin_inset Formula $n$
\end_inset

 steps you sum the probabilities of all paths that take you from 
\begin_inset Formula $i$
\end_inset

 to 
\begin_inset Formula $j$
\end_inset

 in 
\begin_inset Formula $n$
\end_inset

 steps.
 Next the prob of each path is the prob of an intersection of the form 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula 
\begin{eqnarray*}
P\left[A_{1}\cap A_{2}...A_{n}\right] & = & P\left[A_{n}|A_{1}\cap A_{2}\ldots A_{n-1}\right]*P\left[A_{1}\cap A_{2}\ldots A_{n-1}\right]\\
 & = & P\left[A_{n}|A_{n-1}\right]*P\left[A_{n-1}|A_{n-2}\right]*\ldots*P\left[A_{1}\right]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Let
\begin_inset Formula $P_{ij}^{n+m}$
\end_inset

be 
\begin_inset Formula $P[X_{m+n}=j|X_{0}=i]$
\end_inset


\end_layout

\begin_layout Standard
It is easy to see that the Markov property is satisfied (check this formality).
\end_layout

\begin_layout Standard
In this case we have : 
\end_layout

\begin_layout Standard
-- 0- 1- 2- ....
 N 
\end_layout

\begin_layout Standard
0 1 - 0- 0- 0- 0 
\end_layout

\begin_layout Standard
1 1-p - 0 - p ...
\end_layout

\begin_layout Standard
2 0- 1-p - 0- p 
\end_layout

\begin_layout Subsection
The classification of states
\end_layout

\begin_layout Standard
Eventually we'll be studying the limiting behavior of 
\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

as 
\begin_inset Formula $n\rightarrow\infty$
\end_inset

.
 In order to do so require the classification of the states of a Markov
 chain and the classification of the chain themselves
\end_layout

\begin_layout Subsubsection*
Definition: 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left\{ X_{n},n=0,1,2,..\right\} $
\end_inset

 be a Markov chain with transmission matrix 
\begin_inset Formula $P=\{P_{ij}\}.$
\end_inset

Then we say that the state 
\begin_inset Formula $j$
\end_inset

 is accessible from the state 
\begin_inset Formula $i$
\end_inset

, if and only if there exist an 
\begin_inset Formula $n>0$
\end_inset

 s.t.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{ij}^{(n)}>0$
\end_inset

.
 [i.e.
 there is a positive prob of reaching state j from state i in a finite number
 of steps]
\end_layout

\begin_layout Standard
Note that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{ij}^{(n)}$
\end_inset

is not the probability of reaching j from i for the first time in n steps.
 
\end_layout

\begin_layout Standard
We write 
\begin_inset Formula $i\rightarrow j$
\end_inset

 to mean 
\begin_inset Quotes eld
\end_inset

j is accessible from i
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Paragraph
Definition: 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $i\rightarrow j$
\end_inset

 and 
\begin_inset Formula $j\rightarrow i$
\end_inset

 then we say that 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 
\emph on
communicate
\emph default
, and write 
\begin_inset Formula $i\leftrightarrow j$
\end_inset


\end_layout

\begin_layout Paragraph
Theorem:
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $i\leftrightarrow j$
\end_inset

 and 
\begin_inset Formula $j\leftrightarrow k$
\end_inset

, then 
\begin_inset Formula $i\rightarrow k$
\end_inset

 and conversely
\end_layout

\begin_layout Subparagraph
Corollary: 
\begin_inset Formula $i\leftrightarrow j\wedge j\leftrightarrow k\Rightarrow i\leftrightarrow k$
\end_inset


\end_layout

\begin_layout Standard
Proof: 
\begin_inset Formula $i\rightarrow j\Rightarrow\exists n_{0}>0$
\end_inset

 such that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{ij}^{(n)}>0$
\end_inset

 and 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $j\rightarrow k\Rightarrow\exists n_{1}$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 such that 
\begin_inset Formula $P_{jk}^{(n)}>0$
\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $n=n_{0}+n_{1}$
\end_inset


\end_layout

\begin_layout Standard
Then 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{ik}^{(n)}=P_{ik}^{(n_{0}+n_{1})}=\sum_{l}P_{il}^{(n_{0})}*P_{lk}^{(n_{1})}\geq P_{ij}^{(n_{0})}*P_{jk}^{(n_{1})}>0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $i\rightarrow k$
\end_inset

 done!
\end_layout

\begin_layout Standard
The corollary is immediate same 
\begin_inset Formula $i\leftrightarrow j\Rightarrow j\leftrightarrow j$
\end_inset


\end_layout

\begin_layout Subsubsection
Definition of states
\end_layout

\begin_layout Standard
Given a state j of a Markov chain, its communicating class 
\begin_inset Formula $C{}_{j}$
\end_inset

 is defined to be the set of all state that communicate with 
\begin_inset Formula $j$
\end_inset

, in the sense that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{jk}^{(n)}>0$
\end_inset

 for some 
\begin_inset Formula $n_{0}>0$
\end_inset

 
\begin_inset Formula $P_{kj}^{(n)}>0$
\end_inset

 for some 
\begin_inset Formula $n_{1}>0.$
\end_inset

 It may happen that 
\begin_inset Formula $C_{j}$
\end_inset

 is empty [i.e.
 j communicates with no state, not even with itself].
 In this case we say that 
\begin_inset Formula $\left\{ j\right\} $
\end_inset

 is a non-return state.
 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $C_{j}$
\end_inset

 is non-empty, then, 
\begin_inset Formula $j\in C_{oj}$
\end_inset

, to see this note that 
\begin_inset Formula $C_{j}$
\end_inset

 non empty implies that there must exist a.k such that 
\begin_inset Formula $j\rightarrow k$
\end_inset

 (and 
\begin_inset Formula $k\rightarrow j$
\end_inset

)
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\exists n_{0}\,:\,P_{jk}^{(n0)}>0$
\end_inset

 and 
\begin_inset Formula $\exists n_{1}\,:\,P_{kj}^{(n1)}>0$
\end_inset

.
 Let 
\begin_inset Formula $n=n_{0}+n_{1}$
\end_inset

.
 Then 
\begin_inset Formula $P_{jj}^{(n)}\geq P_{jk}^{(n0)}P_{kj}^{(n1)}>0$
\end_inset

.
 
\begin_inset Formula $j$
\end_inset

 communicates with itself, and this 
\begin_inset Formula $j\in C_{j}$
\end_inset


\end_layout

\begin_layout Standard
A state which communicates with itself is called 
\emph on
return state
\emph default
.
 A non-empty class, 
\begin_inset Formula $C$
\end_inset

 of state in a Markov chain is to be a 
\emph on
communicating class
\emph default
 if for some state 
\begin_inset Formula $j$
\end_inset

 s.t 
\begin_inset Formula $C_{k}=C$
\end_inset

 .
 That is 
\begin_inset Formula $C$
\end_inset

 is the class of all states that communicate with one-another
\end_layout

\begin_layout Subsubsection*
Theorem: 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $C_{1}$
\end_inset

and 
\begin_inset Formula $C_{2}$
\end_inset

are communicating classes, then either 
\begin_inset Formula $C_{1}=C_{2}$
\end_inset

or 
\begin_inset Formula $C_{1}\cap C_{2}=Ø$
\end_inset


\end_layout

\begin_layout Subsubsection*
Proof: 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $C_{1}\cap C_{2}\neqØ$
\end_inset

 such that 
\begin_inset Formula $C_{1}\neqØ$
\end_inset

 and 
\begin_inset Formula $C_{2}\neqØ$
\end_inset

 so 
\begin_inset Formula $\exists i\in C_{2}\,\exists j\in C_{1}\cap C_{2}$
\end_inset

 but 
\begin_inset Formula $C_{1}\cap C_{2}\subset C_{1}$
\end_inset

so 
\begin_inset Formula $i\leftrightarrow j$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\exists i\in C_{1}\\
\exists j\in C_{1}\cap C_{2}\\
\exists k\in C_{2}\\
\mbox{but}\\
C_{1}\cap C_{2}\subset C_{1}\\
C_{1}\cap C_{2}\subset C_{2}\\
\therefore i\rightarrow j\\
\therefore j\rightarrow k\\
\therefore i\rightarrow k & \mbox{transitivity of "accessibility"}\\
\therefore C_{1}\subset C_{2}\wedge C_{2}\subset C_{1}\\
\therefore C_{1}=C_{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsection
Decomposition of a Markov chain into disjoint classes
\end_layout

\begin_layout Subsubsection*
Theorem: 
\end_layout

\begin_layout Standard
The set 
\begin_inset Formula $S$
\end_inset

 of states of a Markov chain can be written as the union of a finite or
 countably infinite family 
\begin_inset Formula $\left\{ C_{r}\right\} $
\end_inset

of disjoint sets of states.
 
\begin_inset Formula $S=C_{1}\cup C_{2}...\cup C_{r}$
\end_inset

 with 
\begin_inset Formula $C_{i}\cap C_{2}=Ø$
\end_inset


\end_layout

\begin_layout Standard
Each class 
\begin_inset Formula $C_{r}$
\end_inset

 is either a communicating class or contains exactly one non return state
 
\end_layout

\begin_layout Subsubsection*
Proof 
\end_layout

\begin_layout Standard
Choose a state 
\begin_inset Formula $j_{1}$
\end_inset

 and let 
\begin_inset Formula $C_{1}=C_{j_{1}}$
\end_inset

, the class of all the states that communicate with 
\begin_inset Formula $j_{1}$
\end_inset

 according as 
\begin_inset Formula $j_{1}$
\end_inset

 is a return or non-return state, if 
\begin_inset Formula $j_{1}$
\end_inset

 is a non-return state, then set 
\begin_inset Formula $C_{1}=\left\{ j_{1}\right\} $
\end_inset

 
\end_layout

\begin_layout Standard
Then choose 
\begin_inset Formula $j_{2}$
\end_inset

 not in 
\begin_inset Formula $C_{1},$
\end_inset

and let 
\begin_inset Formula $C_{2}=C_{j_{2}}$
\end_inset

or 
\begin_inset Formula $\left\{ j_{2}\right\} $
\end_inset

 depending on whether or not {
\begin_inset Formula $j_{2}\}$
\end_inset

 is a non return state.
 From the previous theorem, 
\begin_inset Formula $C_{1}\cap C_{2}=Ø$
\end_inset

 Continue the construction in this way to get 
\begin_inset Formula $C_{1},C_{2},\ldots$
\end_inset


\end_layout

\begin_layout Standard
A non empty class, 
\begin_inset Formula $C$
\end_inset

, of state is such that to be closed if no state outside 
\begin_inset Formula $C$
\end_inset

 is accessible from any state of 
\begin_inset Formula $C$
\end_inset

.
 
\end_layout

\begin_layout Standard
i.e.
 
\begin_inset Formula $C$
\end_inset

 is closed iff for every for every 
\begin_inset Formula $\forall n>0\,\forall j\in C\,\forall k\notin C\;P_{jk}^{(n)}=0$
\end_inset

, 
\end_layout

\begin_layout Standard
Examples: In the following examples we classify the states of the corresponding
 Markov chains with the given transition matrices.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\begin{bmatrix}1 & 0 & 0 & 0\\
\frac{1}{2} & \frac{1}{2} & 0 & 0\\
\frac{1}{3} & \frac{1}{3} & 0 & \frac{1}{3}\\
\frac{1}{4} & \frac{1}{4} & \frac{1}{4} & \frac{1}{4}
\end{bmatrix}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
{1} closed communicating
\end_layout

\begin_layout Itemize
{2} communication non closed
\end_layout

\begin_layout Itemize
{3-4} communication non closed
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $\begin{bmatrix}1 & 0 & 0 & 0\\
1 & 0 & 0 & 0\\
\frac{1}{2} & \frac{1}{2} & 0 & 0\\
\frac{1}{3} & \frac{1}{3} & \frac{1}{3} & 0
\end{bmatrix}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
{4} non return 
\end_layout

\begin_layout Itemize
{1} closed communicating
\end_layout

\begin_layout Itemize
{2} non return (non closed)
\end_layout

\begin_layout Itemize
{3} non return
\end_layout

\end_deeper
\begin_layout Standard
A 
\emph on
closed communication
\emph default
 class 
\begin_inset Formula $C$
\end_inset

 of states is essentially a Markov chains extracted and studied independently
\end_layout

\begin_layout Standard
If you write the transition matrix so that the states in 
\begin_inset Formula $C$
\end_inset

 are written, then 
\begin_inset Formula $P$
\end_inset

 can be written in the form 
\begin_inset Formula $P=\begin{bmatrix}P_{C} & 0\\
* & *
\end{bmatrix}$
\end_inset

 where 
\begin_inset Formula $*$
\end_inset

 are possibly non-zero matrix and 
\begin_inset Formula $P_{c}$
\end_inset

 is the sub-matrix whose entries are the transition probabilities between
 the states of 
\begin_inset Formula $C$
\end_inset

.
 Then 
\begin_inset Formula $P^{(n)}=P^{n}=\begin{bmatrix}P_{C}^{n} & 0\\
* & *
\end{bmatrix}$
\end_inset


\end_layout

\begin_layout Standard
Since a closed communication class 
\begin_inset Formula $C$
\end_inset

 can be extracted from a Markov chain (by deleting all rows and colons correspon
ding to states outside of 
\begin_inset Formula $C$
\end_inset

) and treated by itself as a Markov chains it follows that for the study
 asymptotic properties of a Markov chain, it is sufficient to restrict one
 self to chains in which there is exactly one closed communicating class
 and all the other communicating class are non closed
\end_layout

\begin_layout Subsection
Further Classification of states.
\end_layout

\begin_layout Standard
In order to obtain certain asymptotic properties of a Markov chain, we shall
 make further classification of states
\end_layout

\begin_layout Paragraph
Definition:
\end_layout

\begin_layout Standard
For any state 
\begin_inset Formula $j,k$
\end_inset

 let 
\begin_inset Formula $f_{jk}$
\end_inset

 denote the probability starting from 
\begin_inset Formula $j$
\end_inset

 the process will get into state 
\begin_inset Formula $k$
\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $g_{kk}$
\end_inset

 denote the probability that the chain will return infinitely often to state
 
\begin_inset Formula $k$
\end_inset

 given that it start in 
\begin_inset Formula $k$
\end_inset


\end_layout

\begin_layout Paragraph
note:
\end_layout

\begin_layout Standard
these definitions can be made mathematically rigorous by introducing the
 r.v 
\begin_inset Formula $N_{k}(n)$
\end_inset

, the number of time that the state 
\begin_inset Formula $k$
\end_inset

 is visited in 
\begin_inset Formula $n$
\end_inset

 step.
 Our descriptive definition will suffice
\end_layout

\begin_layout Paragraph
Definition:
\end_layout

\begin_layout Standard
We denote 
\begin_inset Formula $f_{jk}^{(n)}$
\end_inset

 the conditional probability of entering 
\begin_inset Formula $k$
\end_inset

 from 
\begin_inset Formula $j$
\end_inset

 from the first time in exactly 
\begin_inset Formula $n$
\end_inset

 steps 
\end_layout

\begin_layout Standard
the time it takes to enter 
\begin_inset Formula $k$
\end_inset

 from 
\begin_inset Formula $j$
\end_inset

 for the first time is called the first passage time.
\end_layout

\begin_layout Paragraph
Note:
\end_layout

\begin_layout Standard
\begin_inset Formula $f_{jk}^{(n)}$
\end_inset

 can be made precise by formally saying that if we are to reach 
\begin_inset Formula $k$
\end_inset

 for the first time from 
\begin_inset Formula $j$
\end_inset

 in 
\begin_inset Formula $n$
\end_inset

 steps then the chains must not have visited 
\begin_inset Formula $k$
\end_inset

 in the first 
\begin_inset Formula $n-1$
\end_inset

 steps and then on the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

 step have jumped to state 
\begin_inset Formula $k$
\end_inset


\end_layout

\begin_layout Paragraph
Example:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left\{ X_{n},n=0,1,\ldots\right\} $
\end_inset

 be a 2-states Markov chain (with state 0 and 1) find the 1
\begin_inset script superscript

\begin_layout Plain Layout
st
\end_layout

\end_inset

passage probs 
\begin_inset Formula $f_{jk}^{(n)}.$
\end_inset

 Ex: 
\begin_inset Formula $f_{00}^{(n)}=P_{01}P_{11}^{n-2}P_{10}\,n\geq2$
\end_inset


\end_layout

\begin_layout Paragraph
Proof:
\end_layout

\begin_layout Standard
it's a mistake to say that the product (and power 
\begin_inset Formula $n-2$
\end_inset

) arise because of independence of various event.
 They are certainly independent.
 However we can condition backward and use the Markov property.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
f_{00}^{(n)} & = & P\left[X_{1}=1,X_{2}=1,\ldots,X_{n-1}=1,X_{n}=0|X_{n}=0\right]\\
 & = & P\left[X_{n}=0|X_{0}=0,X_{1}=1,\ldots,X_{n-1}=1\right]P\left[X_{n-1}=1|X_{0}=0,\ldots;,X=1\right]\\
 &  & \cdots P\left[X_{1}=1|X_{0}=0\right]\\
 & = & P\left[X_{n}=0|X_{n-1}=1\right]P\left[X_{n-1}=1|X_{n-2}=1\right]\cdots P\left[X_{1}=1|X_{0}=0\right]\\
 &  & \mbox{[We used Markov property]}\\
 & = & P_{01}P_{11}^{n-2}P_{10}\\
 &  & \mbox{[We used Homogeneity}]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The other 
\begin_inset Formula $f_{jk}^{(n)}$
\end_inset

's follow similarly
\end_layout

\begin_layout Subsubsection*
Theorem:
\end_layout

\begin_layout Standard
For any states 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $k$
\end_inset

 
\begin_inset Formula $f_{jk}=\sum_{n=1}^{\infty}f_{ik}^{(n)}$
\end_inset


\end_layout

\begin_layout Paragraph
Proof:
\end_layout

\begin_layout Standard
Ever entering 
\begin_inset Formula $k$
\end_inset

 from 
\begin_inset Formula $j$
\end_inset

 is the disjoin union of entering 
\begin_inset Formula $k$
\end_inset

 from 
\begin_inset Formula $j$
\end_inset

 in exactly 
\begin_inset Formula $n$
\end_inset

 steps 
\begin_inset Formula $\forall n\geq1$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Theorem:
\end_layout

\begin_layout Standard
For any states 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $k$
\end_inset

 and 
\begin_inset Formula $n\geq1$
\end_inset

 
\begin_inset Formula $P_{jk}^{(n)}=\sum_{m=1}^{n}f_{jk}^{(m)}P_{kk}^{m-n}$
\end_inset


\end_layout

\begin_layout Paragraph
Proof: 
\end_layout

\begin_layout Standard
If you are in state 
\begin_inset Formula $k$
\end_inset

 (starting in 
\begin_inset Formula $j$
\end_inset

) 
\emph on
at
\emph default
 the n
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

step then you must have entered 
\begin_inset Formula $k$
\end_inset

 for the 1
\begin_inset script superscript

\begin_layout Plain Layout
st
\end_layout

\end_inset

at some 
\begin_inset Formula $m$
\end_inset

 and then in the remaining 
\begin_inset Formula $n-m$
\end_inset

 step, be in state 
\begin_inset Formula $k$
\end_inset

 (starting from 
\begin_inset Formula $k$
\end_inset

)
\end_layout

\begin_layout Standard
we're talking of a disjoin union of these events.
 again we use the Markov property and homogeneity to get the product
\end_layout

\begin_layout Subsubsection*
Theorem: 
\end_layout

\begin_layout Standard
For any state 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $k$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
g_{kk} & = & \lim_{n\rightarrow\infty}\left(f_{kk}\right)^{n}\label{eq:A}\\
g_{jk} & = & f_{jk}g_{kk}\nonumber 
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Paragraph
proof:
\end_layout

\begin_layout Standard
\begin_inset Formula $g_{kk}=\lim_{n\rightarrow\infty}P\left[\mbox{every returning to \ensuremath{k}from 1th \ensuremath{k}}\cap\mbox{ever returning from the second }k\cap\ldots\cap\mbox{ever returning from the nth}k\right]$
\end_inset


\end_layout

\begin_layout Standard
Now condition backward.
 
\end_layout

\begin_layout Subsubsection*
Theorem
\end_layout

\begin_layout Standard
For any state 
\begin_inset Formula $k$
\end_inset

 either 
\begin_inset Formula $g_{kk}=0$
\end_inset

 or 
\begin_inset Formula $g_{kk}=1$
\end_inset

, further 
\end_layout

\begin_layout Standard
\begin_inset Formula $g_{kk}=0\Leftrightarrow f_{kk}<1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g_{kk}=1\Leftrightarrow f_{kk}=1$
\end_inset


\end_layout

\begin_layout Standard
Proof follows directly from 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:A"

\end_inset


\end_layout

\begin_layout Standard
After all this background we come to en important theorem: Theorem [A zero-one|a
w]
\end_layout

\begin_layout Section
Application to Branching process
\end_layout

\begin_layout Standard
We show that in a simple (
\noun on
galton-watson
\noun default
) Branching process, the successive generation size either tend to infinity
 with probability 
\begin_inset Formula $1$
\end_inset

 or die out with probability 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $g_{kk}$
\end_inset

 be the prob that the chain returns infinitely often to the state 
\begin_inset Formula $k$
\end_inset

 we shall show that 
\begin_inset Formula $g_{kk}=0\,\forall k=0,1,\ldots$
\end_inset

 that is no matter what finite set of state you choose, you will visit these
 states only a finite number of times.
\end_layout

\begin_layout Standard
To proves this all we need to do is show that 
\begin_inset Formula $f_{kk}<1$
\end_inset


\end_layout

\begin_layout Standard
<<<<<<< HEAD<<<<<<< HEAD=======>>>>>>> origin/master
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
<<<<<<< HEADg_{kk} = 
\begin_inset Formula $lim_{\infty}(f_{kk})^{n}$ ======= 

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g_{jk}=f_{jk}*g_{kk}$
\end_inset

<<<<<<< HEAD to prove 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
g_{kk}=0 for k=1,2, all we need to do is to show that 
\begin_inset Formula $f_{kk}<1,$
\end_inset

 k=1,2..
\end_layout

\begin_layout Standard
Now, 
\begin_inset Formula $f_{kk}$
\end_inset

= prob of ever return to k from k
\end_layout

\begin_layout Standard
The event denote A {ever return to K from K} 
\begin_inset Formula $\subset$
\end_inset

(denote B) { not goint to 0 in the next generationfrom a generation of size
 k}
\end_layout

\begin_layout Standard
P(A)
\begin_inset Formula $\leq$
\end_inset

P(B) = A - (
\begin_inset Formula $P_{0})^{k}$
\end_inset

 where po = prob a parent wil have children
\end_layout

\begin_layout Standard
(
\begin_inset Formula $P_{0})^{k}$
\end_inset

 = prob that all parent will have 1 children (independant of the number
 of children per parent)
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $P_{0}$
\end_inset

>0, then 
\begin_inset Formula $f_{kk}\leq$
\end_inset

1 - (
\begin_inset Formula $p_{0})^{k}<1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g_{kk}=0$
\end_inset

 If 
\begin_inset Formula $p_{0}>0,$
\end_inset

 there is zero probability of making infinitely many returns to any positive
 state.
 (generation size).
 That is, either the gen sizes tend to infinity (may not monotonically)
 or a gen.
 w/ no individuals (
\begin_inset Formula $X_{n}=0)$
\end_inset

is reached, in whcih case, of course, the state 0 will be visited thereafter.
 What abotu the case 
\begin_inset Formula $P_{0}=0?$
\end_inset

 The above argument gives 
\begin_inset Formula $f_{kk}\leq1-0=1$
\end_inset

which is not informative.
 However, this is the trivial case since each parent has at least 1 child
 and the generation size must then increase to infinity.
\end_layout

\begin_layout Standard
The following theorem help us decide wheter 
\begin_inset Formula $f_{kk}<1$
\end_inset

 of 
\begin_inset Formula $f_{kk}=1$
\end_inset


\end_layout

\begin_layout Standard
Theorem : For any state in a Markov chain, 
\begin_inset Formula $f_{kk}<1$
\end_inset

 <=> 
\begin_inset Formula $\sum_{n=1}p_{kk}^{(n)}<\infty$
\end_inset

, 
\end_layout

\begin_layout Standard
and 
\begin_inset Formula $f_{kk}=1$
\end_inset

 <=> 
\begin_inset Formula $\sum_{n=1}^{\infty}$
\end_inset


\begin_inset Formula $p_{kk}^{(n)}$
\end_inset

= +
\begin_inset Formula $\infty$
\end_inset

 (will not be proven : uses much analysis)
\end_layout

\begin_layout Standard
proof sketch
\end_layout

\begin_layout Standard
Lemma: Let 
\begin_inset Formula $p_{jk}(z)=\sum_{n=0}^{\infty}z^{n}p_{jk}^{(n)}=d_{jk}+\sum_{n=1}^{\infty}$
\end_inset

z
\begin_inset Formula $^{n}p_{jk}^{(n)}$
\end_inset

where 
\begin_inset Formula $d_{jk}=$
\end_inset

1 if j=K and 0 otherwise
\end_layout

\begin_layout Standard
let 
\begin_inset Formula $F_{jk}(z)$
\end_inset

=
\begin_inset Formula $\sum_{n=1}^{\infty}z^{n}f_{jk}^{(n)}$
\end_inset

 
\begin_inset Formula $P_{jk}(z)$
\end_inset

 cd 
\begin_inset Formula $F_{jk}(z)$
\end_inset

 are defined for |z|<1 There are called generating function
\end_layout

\begin_layout Standard
Proof |
\begin_inset Formula $P_{jk(z)}|$
\end_inset


\begin_inset Formula $\leq\sum_{n=0}^{\infty}|z|^{n}p_{jk}^{(n)}$
\end_inset


\begin_inset Formula $\leq$
\end_inset


\begin_inset Formula $\sum_{n=0}^{\infty}|z|^{(n)}$
\end_inset

 ======= 
\end_layout

\begin_layout Standard
To prove >>>>>>> origin/master
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
<<<<<<< HEAD
\begin_inset Formula $p_{jk}^{(n)}$
\end_inset

 
\begin_inset Formula $\leq1$
\end_inset

 which converges if |z|
\begin_inset Formula $<1$
\end_inset

(gemometric series)
\end_layout

\begin_layout Standard
Similirly for 
\begin_inset Formula $F_{jk}(z)$
\end_inset


\end_layout

\begin_layout Standard
Theorem : For any two states j and is a MC and |z|<1
\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $P_{kk}(z)=Fjk(z)P_{kk}(z)$
\end_inset

 if j different k
\end_layout

\begin_layout Standard
(2) 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{kk}$
\end_inset

(z)=1=
\begin_inset Formula $F_{kk}(z)P_{kk}(z)$
\end_inset


\end_layout

\begin_layout Standard
(3) 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P_{kk}$
\end_inset

(z)= 1/1-
\begin_inset Formula $F_{kk}(z)$
\end_inset

, 
\begin_inset Formula $F_{kk}$
\end_inset

(z)=1- 1/
\begin_inset Formula $P_{kk}(z)$ ======= -------------------------------------------------------------------------------- ------------------------------ ======= 

\end_inset

 for k=1,2, all we need to do is to show that 
\begin_inset Formula $f_{kk}<1,\,k=1,2,\ldots$
\end_inset


\end_layout

\begin_layout Standard
Now, 
\begin_inset Formula $f_{kk}$
\end_inset

= prob of ever return to k from k
\end_layout

\begin_layout Standard
The event denote A {ever return to K from K} 
\begin_inset Formula $\subset$
\end_inset

(denote B) { not goint to 0 in the next generation from a generation of
 size k}
\end_layout

\begin_layout Standard
\begin_inset Formula $P(A)\leq P(B)=1-(P_{0})^{k}$
\end_inset

where 
\begin_inset Formula $P_{0}$
\end_inset

 = prob a parent wil have children
\end_layout

\begin_layout Standard
\begin_inset Formula $(P_{0})^{k}$
\end_inset

 = prob that all parent will have 1 children (independant of the number
 of children per parent)>>>>>>> origin/master
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $P_{0}>0$
\end_inset

, then 
\begin_inset Formula $f_{kk}\leq1-(p_{0})^{k}<1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g_{kk}=0$
\end_inset

 If 
\begin_inset Formula $p_{0}>0,$
\end_inset

 there is zero probability of making infinitely many returns to any positive
 state.
 (generation size).
 That is, either the generation sizes tend to infinity (may not monotonically)
 or a generation w/ no individuals (
\begin_inset Formula $X_{n}=0)$
\end_inset

 is reached, in which case, of course, the state 0 will be visited thereafter.
 What about the case 
\begin_inset Formula $P_{0}=0$
\end_inset

? The above argument gives 
\begin_inset Formula $f_{kk}\leq1-0=1$
\end_inset

 which is not informative.
 However, this is the trivial case since each parent has at least 1 child
 and the generation size must then increase to infinity.
\end_layout

\begin_layout Standard
The following theorem help us decide whether 
\begin_inset Formula $f_{kk}<1$
\end_inset

 of 
\begin_inset Formula $f_{kk}=1$
\end_inset


\end_layout

\begin_layout Section
Theorem 100
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
f_{kk}<1 & \Leftrightarrow & \sum_{n=1}^{\infty}P_{kk}^{(n)}<\infty\nonumber \\
f_{kk}=1 & \Leftrightarrow & \sum_{n=1}^{\infty}P_{kk}^{(n)}=+\infty\label{eq:th100}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Subsubsection*
proof:
\end_layout

\begin_layout Standard
let's set 
\begin_inset Formula $P_{jk}(z)=\sum_{n=0}^{\infty}z^{n}P_{jk}^{(n)}$
\end_inset

 and 
\begin_inset Formula $F_{jk}(z)=\sum_{n=0}^{\infty}z^{n}f_{jk}^{(n)}$
\end_inset


\end_layout

\begin_layout Standard
Claim: 
\begin_inset Formula 
\begin{equation}
P_{kk}(z)=\frac{1}{1+F_{kk}(z)}\;,\,F_{kk}(z)=1-\frac{1}{P_{kk}(z)}\label{eq:71}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph
Idea of how 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:71"

\end_inset

 is used to prove theorem 100 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:th100"

\end_inset

.
\end_layout

\begin_layout Standard
For the moment accept the following argument which is actually false.
\end_layout

\begin_layout Standard
using 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:71"

\end_inset

, we have 
\begin_inset Formula $F_{kk}(1)=1-\frac{1}{P_{kk}(1)}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We note that 
\begin_inset Formula $F_{jk}(1)=f_{kk}=\sum_{n=0}^{\infty}f_{jk}^{(n)}$
\end_inset

 and 
\begin_inset Formula $P_{jk}(1)=\sum_{n=0}^{\infty}P_{jk}^{(n)}$
\end_inset

.
\end_layout

\begin_layout Standard
Thus 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:71"

\end_inset

 says 
\begin_inset Formula $f_{kk}=1-\frac{1}{\sum_{n=0}^{\infty}P_{kk}^{(n)}}$
\end_inset

 
\end_layout

\begin_layout Standard
We see immediatly that 
\begin_inset Formula $f_{kk}<1\Leftrightarrow\sum_{n=1}^{\infty}P_{kk}^{(n)}<\infty$
\end_inset

 and 
\begin_inset Formula $f_{kk}=1\Leftrightarrow\sum_{n=1}^{\infty}P_{kk}^{(n)}=+\infty$
\end_inset


\end_layout

\begin_layout Standard
Now this argument is flowed since neither 
\begin_inset Formula $P_{kk}(z)$
\end_inset

 nor 
\begin_inset Formula $F_{kk}(z)$
\end_inset

 is defined for 
\begin_inset Formula $z=1$
\end_inset

.
 To get around this difficulty we need a result in analysis that allows
 us to consider 
\begin_inset Formula $\lim_{z\uparrow1}P_{kk}(1)$
\end_inset

 and 
\begin_inset Formula $\lim_{z\uparrow1}F_{kk}(1)$
\end_inset


\end_layout

\begin_layout Standard
There is an inportant limit theorem that will be used shortly:
\end_layout

\begin_layout Standard
For any state 
\begin_inset Formula $k$
\end_inset

, define 
\begin_inset Formula $m_{kk}=\sum_{n=1}^{\infty}nf_{kk}^{(n)}$
\end_inset


\end_layout

\begin_layout Subsection
Rigorous proof
\end_layout

\begin_layout Paragraph
Theorem: 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $k$
\end_inset

 be any state such that 
\begin_inset Formula $f_{kk}=1$
\end_inset

 and 
\begin_inset Formula $m_{kk}<\infty$
\end_inset

.
 We call 
\begin_inset Formula $m_{kk}$
\end_inset

 the expected (or mean) recurence (return) time to state 
\begin_inset Formula $k$
\end_inset

.
 Then 
\begin_inset Formula 
\begin{eqnarray}
\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{m=1}^{n}P_{kk}^{(m)} & = & \frac{1}{m_{kk}}\label{eq:80}\\
\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{m=1}^{n}P_{jk}^{(m)} & = & f_{jk}\frac{1}{m_{kk}}\label{eq:81}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Paragraph
Proof:
\end_layout

\begin_layout Standard
A rigorous proof use generating function once again and a quite deep theorem
 in analysis.
\end_layout

\begin_layout Standard
However we can give a plausible argument as to why 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:80"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:81"

\end_inset

 might be true.
\end_layout

\begin_layout Paragraph
Recall the (weak) law of large numbers:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X_{1},X_{2}$
\end_inset

 be i.i.d r.v.s with 
\begin_inset Formula $E(X)=\mu<\infty$
\end_inset

 then 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}X_{i}\rightarrow\mu$
\end_inset

 as 
\begin_inset Formula $n\rightarrow\infty$
\end_inset


\end_layout

\begin_layout Paragraph
The strong law of large numbers:
\end_layout

\begin_layout Standard
Under the same assumption 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}X_{i}(w)\rightarrow\mu$
\end_inset

 as 
\begin_inset Formula $n\rightarrow\infty$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

 (almost surely)
\end_layout

\begin_layout Paragraph
Plausible argument
\end_layout

\begin_layout Standard
Let the chain run until we made 
\begin_inset Formula $n$
\end_inset

 return to 
\begin_inset Formula $k$
\end_inset

 (from 
\begin_inset Formula $k$
\end_inset

) this will require a random number of steps in the chain.
 Call this random number 
\begin_inset Formula $N_{kk}(n)$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $T_{i}(k)$
\end_inset

, for 
\begin_inset Formula $i=1,2,\ldots$
\end_inset

 be the observed return time to state 
\begin_inset Formula $k$
\end_inset

 .
 The 
\begin_inset Formula $T_{i}(k)$
\end_inset

's are easily seen to be i.i.d r.v.s Then the observed proportion of time that
 the chain is in state 
\begin_inset Formula $k$
\end_inset

 is given by 
\begin_inset Formula $\frac{n}{\underset{N_{kk}(n)}{\underbrace{T_{1}(k)+\cdots+T_{n}(k)}}}$
\end_inset

 we write this as 
\begin_inset Formula $\frac{1}{\frac{1}{n}\sum_{i=1}^{n}T_{i}(k)}$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $n\rightarrow\infty$
\end_inset

 and by the Strong law of large number 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}T_{i}(k)\overset{\mbox{w.p 1}}{\rightarrow}m_{kk}$
\end_inset

 as by definition 
\begin_inset Formula $\left[E\left[T_{i}(k)\right]=m_{kk}\right]$ >>>>>>> origin/master

\end_inset

 and so 
\end_layout

\begin_layout Standard
How does this relate to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:80"

\end_inset

 ?
\end_layout

\begin_layout Standard
We can evaluate the limiting proportion of time spent in state 
\begin_inset Formula $k$
\end_inset

 with a different scheme.
 Now allow the chain to run for 
\begin_inset Formula $n$
\end_inset

 transition
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
I_{m}(k) & = & 0\mbox{ if the chains is in state \ensuremath{k} at the \ensuremath{m^{th}} step}\\
 & = & 0\mbox{ otherwise}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Then 
\begin_inset Formula $\frac{1}{n}\sum_{m=1}^{n}I_{m}(k)$
\end_inset

 is the observed proportion of time that we are in state 
\begin_inset Formula $k$
\end_inset

 (out of 
\begin_inset Formula $n$
\end_inset

 steps)
\end_layout

\begin_layout Standard
We have 
\begin_inset Formula $P\left[I_{m}(k)|X_{0}=k\right]=P_{kk}^{(m)}$
\end_inset

 
\end_layout

\begin_layout Standard
therefore 
\begin_inset Formula $\frac{1}{n}\sum_{m=1}^{n}P_{kk}^{(m)}$
\end_inset

is the expected proportion of times in state 
\begin_inset Formula $k$
\end_inset

 (from 
\begin_inset Formula $k$
\end_inset

) in steps of the chain
\end_layout

\begin_layout Paragraph
Let's put this together
\end_layout

\begin_layout Standard
We had 
\begin_inset Formula $\frac{n}{\sum_{i=1}^{n}T_{i}(k)}\overset{\mbox{w.p 1}}{\rightarrow}\frac{1}{m_{kk}}$
\end_inset

 and so by the dominate convergence theorem 
\begin_inset Formula $E\left[\frac{n}{\sum_{i=1}^{n}T_{i}(k)}\right]\rightarrow E\left[\frac{1}{m_{kk}}\right]=\frac{1}{m_{kk}}$
\end_inset


\end_layout

\begin_layout Standard
i.e by the 1
\begin_inset script superscript

\begin_layout Plain Layout
st
\end_layout

\end_inset

 samplign scheme the expected proportion of time in step 
\begin_inset Formula $k\rightarrow\frac{1}{m_{kk}}$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula $\frac{1}{n}\sum_{m=1}^{n}P_{kk}^{(m)}\rightarrow\frac{1}{m_{kk}}$
\end_inset


\end_layout

\begin_layout Section
Recurrent and Transient states and classes
\end_layout

\begin_layout Paragraph
Definition:
\end_layout

\begin_layout Standard
A state 
\begin_inset Formula $k$
\end_inset

 is said 
\emph on
recurrent
\emph default
 if 
\begin_inset Formula $f_{kk}=1$
\end_inset

.
\end_layout

\begin_layout Paragraph
Definition:
\end_layout

\begin_layout Standard
A state 
\begin_inset Formula $k$
\end_inset

 is said to be 
\emph on
transient
\emph default
 if 
\begin_inset Formula $f_{kk}<1$
\end_inset


\end_layout

\begin_layout Standard
Transient mean that 
\begin_inset Formula $k$
\end_inset

 will be visited only a finitely many time.
\end_layout

\begin_layout Standard
A class of state is said to be recurrent (transient) if all state in it
 are recurrent (transient) 
\end_layout

\begin_layout Paragraph
Theorem: 
\end_layout

\begin_layout Standard
if 
\begin_inset Formula $C$
\end_inset

 is a communicating class of states in a Markov chain, then if any state
 of 
\begin_inset Formula $C$
\end_inset

 is recurrent (transient) then all states in 
\begin_inset Formula $C$
\end_inset

 are recurrent (transient)
\end_layout

\begin_layout Subsubsection*
Example
\end_layout

\begin_layout Standard
As an example consider the simple random walk on the integer.
 
\end_layout

\begin_layout Standard
We shall show that the set of all state is recurent iff 
\begin_inset Formula $p=\frac{1}{2}$
\end_inset

 (an transient if not) 
\end_layout

\begin_layout Paragraph
Proof: 
\end_layout

\begin_layout Standard
first note that by the previous theorem is sufficient to show that the state
 
\begin_inset Formula $0$
\end_inset

 is recurrent iff 
\begin_inset Formula $p=\frac{1}{2}$
\end_inset

 .
 Reason: clearly in the chain all states communicates.
\end_layout

\begin_layout Standard
We prove this claim by using Theorem 100 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:th100"

\end_inset

 to show that 
\begin_inset Formula $\sum_{n=0}^{\infty}P_{kk}^{(n)}$
\end_inset

 iff 
\begin_inset Formula $p=\frac{1}{2}$
\end_inset


\end_layout

\begin_layout Standard
We thus need an expression for 
\begin_inset Formula $P_{kk}^{(n)}$
\end_inset

.
\end_layout

\begin_layout Standard
We first note that 
\begin_inset Formula $P_{kk}^{(2n-1)}=0\,n=1,2,\ldots$
\end_inset


\end_layout

\begin_layout Standard
Theorem : A recurrent communicating class is closed.
 A closed communicating class must possess infinitely manu states.
\end_layout

\begin_layout Standard
Proof: We show that 
\begin_inset Formula $f_{kk}=1$
\end_inset

 and k->j implies 
\begin_inset Formula $f_{jk}=1$
\end_inset

 i.e.
 k<->j [i.e.
 the only way that you can get to a state j is if that if that state is
 in 
\begin_inset Formula $C.$
\end_inset

This implies 
\begin_inset Formula $C$
\end_inset

be closed.
\end_layout

\begin_layout Standard
Proof: Intuitively does this seem right.
 Well, we know that there is a path from k to j with positive prob.
 This cannot be a 
\begin_inset Quotes eld
\end_inset

bad
\begin_inset Quotes erd
\end_inset

 path, in the sense that with w.p.
 we can get back to k from j, since we would not be able to say w.p.
 1 we can g from k to k.
 Thus we must have that j -> k i.e.
 k<->j.
\end_layout

\begin_layout Standard
Formalities: For any state k and integer n , 
\begin_inset Formula $g_{kk}=\sum_{allstates}p_{ki}^{(n)}g_{ik}$
\end_inset

 (obvious + you have to be somewhere after n steps (starting in k) and then
 make infinitely many returns to k from that 
\begin_inset Quotes eld
\end_inset

somewhere
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Standard
1-
\begin_inset Formula $g_{kk}$
\end_inset

 = 
\begin_inset Formula $\sum_{allstates}p_{ki}^{(n)}(1-\mbox{g\_ik})$
\end_inset

 since 
\begin_inset Formula $g_{kk}=1,$
\end_inset

 1-
\begin_inset Formula $g_{kk}=0$
\end_inset

 and hence, 
\begin_inset Formula $\sum_{states}p_{ki}^{(n)}\{1-g_{ik}\}$
\end_inset

 for every n
\end_layout

\begin_layout Standard
Now return to thr state j that we were considering since k->j, 
\begin_inset Formula $\exists$
\end_inset

 an N such that 
\begin_inset Formula $p(N\text{)}_{kj}>0.$
\end_inset

It follows that (1-
\begin_inset Formula $g_{jk})=0$
\end_inset

 i.e.
 
\begin_inset Formula $g_{jk}=1$
\end_inset

.
 Now, 
\begin_inset Formula $g_{jk}=$
\end_inset


\begin_inset Formula $f_{jk}g_{kk}$
\end_inset

means that if k is reccurent and hence 
\begin_inset Formula $g_{kk}=1$
\end_inset

 we mush have 
\begin_inset Formula $f_{jk}=1,$
\end_inset

 which is what we wanyed to show.
\end_layout

\end_body
\end_document
